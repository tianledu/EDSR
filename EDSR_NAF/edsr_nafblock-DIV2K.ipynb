{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663e700c-fd96-45d1-86b1-7b218e778585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SRDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, crop_size, scaling_factor):\n",
    "        # 参数：图片路径、裁剪尺寸、放大倍数\n",
    "        self.data_path = data_path\n",
    "        self.crop_size = int(crop_size)\n",
    "        self.scaling_factor = int(scaling_factor)\n",
    "        self.images_path = []\n",
    "\n",
    "\n",
    "        # 读取图像路径\n",
    "        for name in os.listdir(self.data_path):\n",
    "            self.images_path.append(os.path.join(self.data_path, name))\n",
    "\n",
    "        # 数据处理方式\n",
    "        self.pre_trans = transforms.Compose([\n",
    "            transforms.RandomCrop(self.crop_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "        ])\n",
    "\n",
    "        self.input_transform = transforms.Compose([\n",
    "            transforms.Resize(self.crop_size // self.scaling_factor),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "        self.target_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 读取图像\n",
    "        img = Image.open(self.images_path[i]).convert('RGB')\n",
    "        img = self.pre_trans(img)\n",
    "\n",
    "        lr_img = self.input_transform(img)\n",
    "        hr_img = self.target_transform(img.copy())\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36b108e-4ec0-48c2-9c2d-2bdb9268b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "class LayerNormFunction(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight, bias, eps):\n",
    "        ctx.eps = eps\n",
    "        N, C, H, W = x.shape\n",
    "        mu = x.mean(dim=1, keepdim=True)\n",
    "        var = ((x - mu) ** 2).mean(dim=1, keepdim=True)\n",
    "        y = (x - mu) / torch.sqrt(var + eps)\n",
    "        ctx.save_for_backward(y, var, weight)\n",
    "        y = weight.view(1, C, 1, 1) * y + bias.view(1, C, 1, 1)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = ctx.eps\n",
    "        N, C, H, W = grad_output.shape\n",
    "        y, var, weight = ctx.saved_tensors\n",
    "        g = grad_output * weight.view(1, C, 1, 1)\n",
    "        mean_g = g.mean(dim=1, keepdim=True)\n",
    "        mean_gy = (g * y).mean(dim=1, keepdim=True)\n",
    "        gx = 1. / torch.sqrt(var + eps) * (g - y * mean_gy - mean_g)\n",
    "        return gx, (grad_output * y).sum(dim=[0, 2, 3]), grad_output.sum(dim=[0, 2, 3]), None\n",
    "\n",
    "\n",
    "class LayerNorm2d(nn.Module):\n",
    "    def __init__(self, channels, eps=1e-6):\n",
    "        super(LayerNorm2d, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(channels))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return LayerNormFunction.apply(x, self.weight, self.bias, self.eps)\n",
    "\n",
    "class SimpleGate(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        return x1 * x2\n",
    "\n",
    "# 特征通道数\n",
    "n_feat = 256\n",
    "kernel_size = 3\n",
    "\n",
    "class SimpleGate(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        return x1 * x2\n",
    "\n",
    "class NAFBlock(nn.Module):\n",
    "    def __init__(self, c, DW_Expand=2, FFN_Expand=2, drop_out_rate=0.):\n",
    "        super().__init__()\n",
    "        dw_channel = c * DW_Expand\n",
    "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=dw_channel, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=dw_channel, out_channels=dw_channel, kernel_size=3, padding=1, stride=1, groups=dw_channel,\n",
    "                               bias=True)\n",
    "        self.conv3 = nn.Conv2d(in_channels=dw_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
    "        \n",
    "        # Simplified Channel Attention\n",
    "        self.sca = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels=dw_channel // 2, out_channels=dw_channel // 2, kernel_size=1, padding=0, stride=1,\n",
    "                      groups=1, bias=True),\n",
    "        )\n",
    "\n",
    "        # SimpleGate\n",
    "        self.sg = SimpleGate()\n",
    "\n",
    "        ffn_channel = FFN_Expand * c\n",
    "        self.conv4 = nn.Conv2d(in_channels=c, out_channels=ffn_channel, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
    "        self.conv5 = nn.Conv2d(in_channels=ffn_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
    "\n",
    "        self.norm1 = LayerNorm2d(c)\n",
    "        self.norm2 = LayerNorm2d(c)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
    "        self.dropout2 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
    "\n",
    "        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
    "        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp\n",
    "\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sg(x)\n",
    "        x = x * self.sca(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        y = inp + x * self.beta\n",
    "\n",
    "        x = self.conv4(self.norm2(y))\n",
    "        x = self.sg(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        return y + x * self.gamma\n",
    "\n",
    "\n",
    "class EDSR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EDSR, self).__init__()\n",
    "\n",
    "        in_ch = 3\n",
    "        num_blocks = 32\n",
    "        c = 256\n",
    "        self.conv1 = nn.Conv2d(in_ch, n_feat, kernel_size, padding=1)\n",
    "\n",
    "        # nafblock\n",
    "        self.body = self.make_layer(NAFBlock, num_blocks, c)\n",
    "        # 扩大\n",
    "        self.conv_up = nn.Conv2d(n_feat, n_feat * 4, kernel_size, padding=1)\n",
    "        self.conv_out = nn.Conv2d(n_feat, in_ch, kernel_size, padding=1)\n",
    "        # resblock\n",
    "        # self.body = self.make_layer(_Res_Block, num_blocks)\n",
    "\n",
    "        # 上采样\n",
    "        self.upsample = nn.Sequential(self.conv_up, nn.PixelShuffle(2))\n",
    "\n",
    "    # 32个naf块\n",
    "    def make_layer(self, block, layers, c):\n",
    "        naf_block = []\n",
    "        for _ in range(layers):\n",
    "            naf_block.append(block(c))\n",
    "        return nn.Sequential(*naf_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.body(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv_out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e7f42-e904-4c5e-a570-d342e9c3fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "未加载原有模型训练\n",
      "Epoch 0. Training loss: 0.03867540670264708 Train psnr 15.928738709123412 dB\n",
      "Epoch 0. Testing loss: 0.015908514814717428 Test psnr18.008697173181258 dB\n",
      "模型更新成功\n",
      "Epoch 1. Training loss: 0.009657988892541382 Train psnr 20.371816356816158 dB\n",
      "Epoch 1. Testing loss: 0.009120427803801638 Test psnr20.6491820647525 dB\n",
      "模型更新成功\n",
      "Epoch 2. Training loss: 0.0068338366282548295 Train psnr 21.919655623267765 dB\n",
      "Epoch 2. Testing loss: 0.008024026440190417 Test psnr21.186508869185428 dB\n",
      "模型更新成功\n",
      "Epoch 3. Training loss: 0.005833972792811038 Train psnr 22.617893712662543 dB\n",
      "Epoch 3. Testing loss: 0.007229125925472805 Test psnr21.553039817498618 dB\n",
      "模型更新成功\n",
      "Epoch 4. Training loss: 0.005696794590014115 Train psnr 22.696025414497264 dB\n",
      "Epoch 4. Testing loss: 0.006495171426130193 Test psnr22.176533437532353 dB\n",
      "模型更新成功\n",
      "Epoch 5. Training loss: 0.005629008637920937 Train psnr 22.940318346511567 dB\n",
      "Epoch 5. Testing loss: 0.006089778617024422 Test psnr22.412512902310308 dB\n",
      "模型更新成功\n",
      "Epoch 6. Training loss: 0.0050577113747988876 Train psnr 23.20471855359246 dB\n",
      "Epoch 6. Testing loss: 0.006272473172949893 Test psnr22.116734324605325 dB\n",
      "Epoch 7. Training loss: 0.005029828783957974 Train psnr 23.35587156102629 dB\n",
      "Epoch 7. Testing loss: 0.005323291855997273 Test psnr22.892802306120014 dB\n",
      "模型更新成功\n",
      "Epoch 8. Training loss: 0.0047296677887635795 Train psnr 23.575535835587935 dB\n",
      "Epoch 8. Testing loss: 0.007094357229237046 Test psnr21.78404679617368 dB\n",
      "Epoch 9. Training loss: 0.005184160900841418 Train psnr 23.352506265400077 dB\n",
      "Epoch 9. Testing loss: 0.0068155779237193724 Test psnr22.269495818192393 dB\n",
      "Epoch 10. Training loss: 0.0047831425990647915 Train psnr 23.610807492500214 dB\n",
      "Epoch 10. Testing loss: 0.00670337094925344 Test psnr22.036801842453123 dB\n",
      "Epoch 11. Training loss: 0.004990952749115725 Train psnr 23.364680621669265 dB\n",
      "Epoch 11. Testing loss: 0.006581630524513977 Test psnr22.084234078116708 dB\n",
      "Epoch 12. Training loss: 0.0045301294272863555 Train psnr 23.986458489603276 dB\n",
      "Epoch 12. Testing loss: 0.005258591479754874 Test psnr23.04551612745271 dB\n",
      "模型更新成功\n",
      "Epoch 13. Training loss: 0.0050615797313583785 Train psnr 23.298798673489145 dB\n",
      "Epoch 13. Testing loss: 0.00645561542894159 Test psnr22.325011959918385 dB\n",
      "Epoch 14. Training loss: 0.004536876401847653 Train psnr 23.852363805598742 dB\n",
      "Epoch 14. Testing loss: 0.00625173537991941 Test psnr22.59324610617862 dB\n",
      "Epoch 15. Training loss: 0.005071208793915024 Train psnr 23.56549648451189 dB\n",
      "Epoch 15. Testing loss: 0.0044770492573401755 Test psnr23.679916242570748 dB\n",
      "模型更新成功\n",
      "Epoch 16. Training loss: 0.004865107984331094 Train psnr 23.5324753343453 dB\n",
      "Epoch 16. Testing loss: 0.007434376216094408 Test psnr22.06975112403096 dB\n",
      "Epoch 17. Training loss: 0.004864040747889432 Train psnr 23.539136390823536 dB\n",
      "Epoch 17. Testing loss: 0.005256953682484371 Test psnr23.1094930373882 dB\n",
      "Epoch 18. Training loss: 0.0045798420191235974 Train psnr 23.873999324459632 dB\n",
      "Epoch 18. Testing loss: 0.0062275956318314585 Test psnr22.490001961393766 dB\n",
      "Epoch 19. Training loss: 0.004456577689811718 Train psnr 23.99426228382376 dB\n",
      "Epoch 19. Testing loss: 0.0067876047853912625 Test psnr22.15694391277587 dB\n",
      "Epoch 20. Training loss: 0.004815542435257189 Train psnr 23.67205999640683 dB\n",
      "Epoch 20. Testing loss: 0.004785839235410094 Test psnr23.397977835211545 dB\n",
      "Epoch 21. Training loss: 0.004568200442008674 Train psnr 23.929654893790527 dB\n",
      "Epoch 21. Testing loss: 0.005058351471754057 Test psnr23.176737317432963 dB\n",
      "Epoch 22. Training loss: 0.004482476326653309 Train psnr 23.876697840653193 dB\n",
      "Epoch 22. Testing loss: 0.0050951828182275805 Test psnr23.211140799814764 dB\n",
      "Epoch 23. Training loss: 0.0046280962558005725 Train psnr 23.65657781525231 dB\n",
      "Epoch 23. Testing loss: 0.005434933617444975 Test psnr22.888640240724193 dB\n",
      "Epoch 24. Training loss: 0.004556937396460981 Train psnr 23.80403470096614 dB\n",
      "Epoch 24. Testing loss: 0.005972051128212895 Test psnr22.4543940438731 dB\n",
      "Epoch 25. Training loss: 0.004346210299174122 Train psnr 24.171153155019283 dB\n",
      "Epoch 25. Testing loss: 0.005537299406049507 Test psnr22.80053853344267 dB\n",
      "Epoch 26. Training loss: 0.0041388673421910455 Train psnr 24.16068742156608 dB\n",
      "Epoch 26. Testing loss: 0.0058127222250082666 Test psnr22.658053253049015 dB\n",
      "Epoch 27. Training loss: 0.004350429444712701 Train psnr 24.0322906054589 dB\n",
      "Epoch 27. Testing loss: 0.004609863623045385 Test psnr23.767653687148634 dB\n",
      "模型更新成功\n",
      "Epoch 28. Training loss: 0.004393928945718105 Train psnr 23.904030285109794 dB\n",
      "Epoch 28. Testing loss: 0.0058350458608141965 Test psnr22.66568012070437 dB\n",
      "Epoch 29. Training loss: 0.004208257344240944 Train psnr 24.11841891329788 dB\n",
      "Epoch 29. Testing loss: 0.004640781287369984 Test psnr23.578051707454737 dB\n",
      "Epoch 30. Training loss: 0.004819795940675887 Train psnr 23.63463471997547 dB\n",
      "Epoch 30. Testing loss: 0.005043853606496539 Test psnr23.164964823830925 dB\n",
      "Epoch 31. Training loss: 0.00450118933191621 Train psnr 23.839791939884602 dB\n",
      "Epoch 31. Testing loss: 0.005901714055133718 Test psnr22.419168243414145 dB\n",
      "Epoch 32. Training loss: 0.004634681357920431 Train psnr 23.726834055896816 dB\n",
      "Epoch 32. Testing loss: 0.004052982332983187 Test psnr24.168316954764503 dB\n",
      "模型更新成功\n",
      "Epoch 33. Training loss: 0.0043153118673025775 Train psnr 24.046656540284133 dB\n",
      "Epoch 33. Testing loss: 0.005119628505781293 Test psnr23.240610258781736 dB\n",
      "Epoch 34. Training loss: 0.004203433270990979 Train psnr 24.27827045996939 dB\n",
      "Epoch 34. Testing loss: 0.006145910592749715 Test psnr22.50108453579806 dB\n",
      "Epoch 35. Training loss: 0.004403299458014469 Train psnr 23.97760805899743 dB\n",
      "Epoch 35. Testing loss: 0.005062497620071683 Test psnr23.314347205905154 dB\n",
      "Epoch 36. Training loss: 0.00395231214433647 Train psnr 24.350155477022984 dB\n",
      "Epoch 36. Testing loss: 0.004783282056450844 Test psnr23.351501587929512 dB\n",
      "Epoch 37. Training loss: 0.004400644831261353 Train psnr 24.008702617186948 dB\n",
      "Epoch 37. Testing loss: 0.004326925346893924 Test psnr24.228666551949825 dB\n",
      "模型更新成功\n",
      "Epoch 38. Training loss: 0.0043197680027795985 Train psnr 23.995900968049092 dB\n",
      "Epoch 38. Testing loss: 0.005271643400192261 Test psnr23.096239030768036 dB\n",
      "Epoch 39. Training loss: 0.004036413111495213 Train psnr 24.394256079017822 dB\n",
      "Epoch 39. Testing loss: 0.004545791407248804 Test psnr23.615502295881498 dB\n",
      "Epoch 40. Training loss: 0.0038495383055864325 Train psnr 24.471066508708255 dB\n",
      "Epoch 40. Testing loss: 0.005881473505204278 Test psnr23.185711305600723 dB\n",
      "Epoch 41. Training loss: 0.004305024629279056 Train psnr 24.16182153082662 dB\n",
      "Epoch 41. Testing loss: 0.004780104067841811 Test psnr23.651444057595153 dB\n",
      "Epoch 42. Training loss: 0.004467547242121215 Train psnr 23.79687483167502 dB\n",
      "Epoch 42. Testing loss: 0.0050843537984681985 Test psnr23.028865842087914 dB\n",
      "Epoch 43. Training loss: 0.003999493934475539 Train psnr 24.308434035302042 dB\n",
      "Epoch 43. Testing loss: 0.004746926283197743 Test psnr23.50548895138356 dB\n",
      "Epoch 44. Training loss: 0.004534121545587192 Train psnr 23.8767736156554 dB\n",
      "Epoch 44. Testing loss: 0.006697877044124263 Test psnr22.306511775394316 dB\n",
      "Epoch 45. Training loss: 0.00424037845049609 Train psnr 24.21470047203191 dB\n",
      "Epoch 45. Testing loss: 0.005488761301551547 Test psnr22.789131335353765 dB\n",
      "Epoch 46. Training loss: 0.004125691689918504 Train psnr 24.187264724049164 dB\n",
      "Epoch 46. Testing loss: 0.00548596922973437 Test psnr22.854701780475803 dB\n",
      "Epoch 47. Training loss: 0.004221153615058907 Train psnr 24.285732014786962 dB\n",
      "Epoch 47. Testing loss: 0.004336226598492691 Test psnr23.797540462021963 dB\n",
      "Epoch 48. Training loss: 0.003921605170737102 Train psnr 24.42996082316967 dB\n",
      "Epoch 48. Testing loss: 0.00603784279831286 Test psnr22.619116513453395 dB\n",
      "Epoch 49. Training loss: 0.004158184289719844 Train psnr 24.129603113906967 dB\n",
      "Epoch 49. Testing loss: 0.005727344292349049 Test psnr22.563172784948765 dB\n",
      "Epoch 50. Training loss: 0.004196504280052818 Train psnr 24.202630582502547 dB\n",
      "Epoch 50. Testing loss: 0.00689506929899965 Test psnr21.951729367202738 dB\n",
      "Epoch 51. Training loss: 0.0040817535318957085 Train psnr 24.239355757569836 dB\n",
      "Epoch 51. Testing loss: 0.005123547444652233 Test psnr23.432448299994125 dB\n",
      "Epoch 52. Training loss: 0.004090449221334175 Train psnr 24.289575182131536 dB\n",
      "Epoch 52. Testing loss: 0.004509363489757691 Test psnr23.743041058639157 dB\n",
      "Epoch 53. Training loss: 0.004017523326502557 Train psnr 24.24654714600177 dB\n",
      "Epoch 53. Testing loss: 0.004949263862467238 Test psnr23.253769930342507 dB\n",
      "Epoch 54. Training loss: 0.004030257352145813 Train psnr 24.3985367437325 dB\n",
      "Epoch 54. Testing loss: 0.005225467661927853 Test psnr23.106539837595562 dB\n",
      "Epoch 55. Training loss: 0.0038332572480532946 Train psnr 24.541315282237996 dB\n",
      "Epoch 55. Testing loss: 0.00483208562114409 Test psnr23.422845972845124 dB\n",
      "Epoch 56. Training loss: 0.004129755876451861 Train psnr 24.296628568760323 dB\n",
      "Epoch 56. Testing loss: 0.005955486059454935 Test psnr22.637039372849156 dB\n",
      "Epoch 57. Training loss: 0.004143907139159478 Train psnr 24.213025805063182 dB\n",
      "Epoch 57. Testing loss: 0.004971931572072208 Test psnr23.49506653776367 dB\n",
      "Epoch 58. Training loss: 0.0037265445612240256 Train psnr 24.683441693740004 dB\n",
      "Epoch 58. Testing loss: 0.004317600961907634 Test psnr24.373274267502616 dB\n",
      "模型更新成功\n",
      "Epoch 59. Training loss: 0.004111612161515248 Train psnr 24.431447631376418 dB\n",
      "Epoch 59. Testing loss: 0.004788599575736693 Test psnr23.52030089166912 dB\n",
      "Epoch 60. Training loss: 0.004044107747623664 Train psnr 24.29251871523254 dB\n",
      "Epoch 60. Testing loss: 0.004340249745707426 Test psnr24.081533723020424 dB\n",
      "Epoch 61. Training loss: 0.0041526806747067 Train psnr 24.251094819690863 dB\n",
      "Epoch 61. Testing loss: 0.005714851797425321 Test psnr22.605716269605676 dB\n",
      "Epoch 62. Training loss: 0.004338792590587808 Train psnr 24.026104324144445 dB\n",
      "Epoch 62. Testing loss: 0.005151158298498818 Test psnr23.193163068877947 dB\n",
      "Epoch 63. Training loss: 0.004322401131503284 Train psnr 23.934656117920333 dB\n",
      "Epoch 63. Testing loss: 0.004400998553527253 Test psnr23.834731935794405 dB\n",
      "Epoch 64. Training loss: 0.0038668178185297733 Train psnr 24.438647735692506 dB\n",
      "Epoch 64. Testing loss: 0.0044454272636877635 Test psnr23.974089383684554 dB\n",
      "Epoch 65. Training loss: 0.004100526821913949 Train psnr 24.30006800465202 dB\n",
      "Epoch 65. Testing loss: 0.0038962138351053 Test psnr24.380444466071417 dB\n",
      "模型更新成功\n",
      "Epoch 66. Training loss: 0.004092553283267638 Train psnr 24.372209869398777 dB\n",
      "Epoch 66. Testing loss: 0.006707504225362625 Test psnr22.50138302027288 dB\n",
      "Epoch 67. Training loss: 0.003994640498013611 Train psnr 24.365107935652404 dB\n",
      "Epoch 67. Testing loss: 0.005042573703186852 Test psnr23.370471751376524 dB\n",
      "Epoch 68. Training loss: 0.0037729256651609353 Train psnr 24.617425940640814 dB\n",
      "Epoch 68. Testing loss: 0.004693356508921299 Test psnr23.498688907930973 dB\n",
      "Epoch 69. Training loss: 0.004362856078762235 Train psnr 23.999452130406173 dB\n",
      "Epoch 69. Testing loss: 0.006360277200915984 Test psnr22.68504309949986 dB\n",
      "Epoch 70. Training loss: 0.004054106018309922 Train psnr 24.268219471907255 dB\n",
      "Epoch 70. Testing loss: 0.005227432153852922 Test psnr23.093119945719902 dB\n",
      "Epoch 71. Training loss: 0.0037523650690880522 Train psnr 24.65845388148706 dB\n",
      "Epoch 71. Testing loss: 0.005675448204523751 Test psnr22.899878683951204 dB\n",
      "Epoch 72. Training loss: 0.00400352118875864 Train psnr 24.42433190576762 dB\n",
      "Epoch 72. Testing loss: 0.0039612880209460855 Test psnr24.511208060615026 dB\n",
      "模型更新成功\n",
      "Epoch 73. Training loss: 0.003647153538431188 Train psnr 24.887700274613465 dB\n",
      "Epoch 73. Testing loss: 0.005058289705110448 Test psnr23.061154213678673 dB\n",
      "Epoch 74. Training loss: 0.0038379874068165294 Train psnr 24.59387935105907 dB\n",
      "Epoch 74. Testing loss: 0.004465196248410004 Test psnr23.663159134251195 dB\n",
      "Epoch 75. Training loss: 0.0040855331411748606 Train psnr 24.592515916232188 dB\n",
      "Epoch 75. Testing loss: 0.005299055449930685 Test psnr23.44419848373644 dB\n",
      "Epoch 76. Training loss: 0.0040671007897655825 Train psnr 24.31049000976726 dB\n",
      "Epoch 76. Testing loss: 0.004162280778733215 Test psnr24.823274670186954 dB\n",
      "模型更新成功\n",
      "Epoch 77. Training loss: 0.0037620873496818697 Train psnr 24.61392138495396 dB\n",
      "Epoch 77. Testing loss: 0.005230568050007735 Test psnr23.10222799735385 dB\n",
      "Epoch 78. Training loss: 0.004216874659616957 Train psnr 24.25698268957728 dB\n",
      "Epoch 78. Testing loss: 0.00488663448153862 Test psnr23.414298845032306 dB\n",
      "Epoch 79. Training loss: 0.0037010623072682505 Train psnr 24.66236373905286 dB\n",
      "Epoch 79. Testing loss: 0.004798537752191935 Test psnr23.283748954009898 dB\n",
      "Epoch 80. Training loss: 0.0039048776451269525 Train psnr 24.5973826266626 dB\n",
      "Epoch 80. Testing loss: 0.008087030645193798 Test psnr21.77104863059023 dB\n",
      "Epoch 81. Training loss: 0.004108639239954452 Train psnr 24.259191713673278 dB\n",
      "Epoch 81. Testing loss: 0.004307775192760995 Test psnr23.727239574374856 dB\n",
      "Epoch 82. Training loss: 0.004009653734484394 Train psnr 24.46898726803219 dB\n",
      "Epoch 82. Testing loss: 0.004217588775125998 Test psnr24.003894513703496 dB\n",
      "Epoch 83. Training loss: 0.003766268773082023 Train psnr 24.818917991668044 dB\n",
      "Epoch 83. Testing loss: 0.005368514585175684 Test psnr23.191228487072998 dB\n",
      "Epoch 84. Training loss: 0.00366393819128637 Train psnr 24.856011010079587 dB\n",
      "Epoch 84. Testing loss: 0.004386085152093854 Test psnr23.94020259464357 dB\n",
      "Epoch 85. Training loss: 0.0038976460499198814 Train psnr 24.37817702129939 dB\n",
      "Epoch 85. Testing loss: 0.006398586589576942 Test psnr22.66031524627425 dB\n",
      "Epoch 86. Training loss: 0.003765845095346633 Train psnr 24.69634522837374 dB\n",
      "Epoch 86. Testing loss: 0.004287762201524207 Test psnr24.17051810318967 dB\n",
      "Epoch 87. Training loss: 0.004111472962489515 Train psnr 24.238687086400386 dB\n",
      "Epoch 87. Testing loss: 0.004619973179485116 Test psnr24.13771123591252 dB\n",
      "Epoch 88. Training loss: 0.004215618352438405 Train psnr 24.164147305453465 dB\n",
      "Epoch 88. Testing loss: 0.004407940997875163 Test psnr24.0791756912371 dB\n",
      "Epoch 89. Training loss: 0.003773273867473268 Train psnr 24.643741285059086 dB\n",
      "Epoch 89. Testing loss: 0.0045068599948925635 Test psnr23.68874197105166 dB\n",
      "Epoch 90. Training loss: 0.0038090853833413697 Train psnr 24.669607417046077 dB\n",
      "Epoch 90. Testing loss: 0.004833950428292155 Test psnr23.256227871642835 dB\n",
      "Epoch 91. Training loss: 0.004055156346957869 Train psnr 24.402995750025642 dB\n",
      "Epoch 91. Testing loss: 0.004489297097149704 Test psnr23.957783768277313 dB\n",
      "Epoch 92. Training loss: 0.0038008380057331045 Train psnr 24.732367789426302 dB\n",
      "Epoch 92. Testing loss: 0.004801295564642974 Test psnr23.395618876801084 dB\n",
      "Epoch 93. Training loss: 0.003655363012129735 Train psnr 24.82790599907171 dB\n",
      "Epoch 93. Testing loss: 0.004211817169561982 Test psnr23.955215847081323 dB\n",
      "Epoch 94. Training loss: 0.003988950304981125 Train psnr 24.402233819736978 dB\n",
      "Epoch 94. Testing loss: 0.004615918966010213 Test psnr23.679869983122916 dB\n",
      "Epoch 95. Training loss: 0.0036747229546962076 Train psnr 24.722368458070157 dB\n",
      "Epoch 95. Testing loss: 0.004320490107472453 Test psnr23.819135619944024 dB\n",
      "Epoch 96. Training loss: 0.003970225246647667 Train psnr 24.539306623300465 dB\n",
      "Epoch 96. Testing loss: 0.007605500452752624 Test psnr21.778448572334224 dB\n",
      "Epoch 97. Training loss: 0.0040238270936370415 Train psnr 24.550987023632267 dB\n",
      "Epoch 97. Testing loss: 0.005363232722239835 Test psnr23.201165501110633 dB\n",
      "Epoch 98. Training loss: 0.003635261885887175 Train psnr 24.877229170644437 dB\n",
      "Epoch 98. Testing loss: 0.004199960202510867 Test psnr23.92771194199464 dB\n",
      "Epoch 99. Training loss: 0.0038251961038137474 Train psnr 24.6401077552145 dB\n",
      "Epoch 99. Testing loss: 0.004362449781703097 Test psnr24.07731069117713 dB\n",
      "Epoch 100. Training loss: 0.003524266941097091 Train psnr 24.912798246682385 dB\n",
      "Epoch 100. Testing loss: 0.005178205402834075 Test psnr23.422475111591808 dB\n",
      "Epoch 101. Training loss: 0.003965239761511616 Train psnr 24.568795224031756 dB\n",
      "Epoch 101. Testing loss: 0.004116600213040199 Test psnr24.162873650847587 dB\n",
      "Epoch 102. Training loss: 0.003888953007398206 Train psnr 24.54179073549299 dB\n",
      "Epoch 102. Testing loss: 0.00457389820699713 Test psnr23.816446964216507 dB\n",
      "Epoch 103. Training loss: 0.0036754807183649717 Train psnr 24.709901209326517 dB\n",
      "Epoch 103. Testing loss: 0.004642810506213989 Test psnr23.596276582114708 dB\n",
      "Epoch 104. Training loss: 0.004126748506422972 Train psnr 24.540102624494146 dB\n",
      "Epoch 104. Testing loss: 0.004595518045659576 Test psnr23.72635195978469 dB\n",
      "Epoch 105. Training loss: 0.003740103433333468 Train psnr 24.698560152170845 dB\n",
      "Epoch 105. Testing loss: 0.004730860103986093 Test psnr23.38570407792352 dB\n",
      "Epoch 106. Training loss: 0.003815107429481781 Train psnr 24.687967385765965 dB\n",
      "Epoch 106. Testing loss: 0.004155077505856752 Test psnr24.05848511948675 dB\n",
      "Epoch 107. Training loss: 0.00380658881591731 Train psnr 24.644648871512143 dB\n",
      "Epoch 107. Testing loss: 0.0042194953254823175 Test psnr24.084337123439774 dB\n",
      "Epoch 108. Training loss: 0.003660188230130364 Train psnr 24.854711845504717 dB\n",
      "Epoch 108. Testing loss: 0.004098718852869102 Test psnr24.211262511734184 dB\n",
      "Epoch 109. Training loss: 0.003826797459879073 Train psnr 24.534903839172806 dB\n",
      "Epoch 109. Testing loss: 0.005186756939760276 Test psnr23.19986143704089 dB\n",
      "Epoch 110. Training loss: 0.003883793196444841 Train psnr 24.45492238033084 dB\n",
      "Epoch 110. Testing loss: 0.003957985135327492 Test psnr24.422455520848708 dB\n",
      "Epoch 111. Training loss: 0.003981082822735372 Train psnr 24.466723515653293 dB\n",
      "Epoch 111. Testing loss: 0.004237224747027669 Test psnr23.875576695306172 dB\n",
      "Epoch 112. Training loss: 0.003810266353467708 Train psnr 24.695358800500973 dB\n",
      "Epoch 112. Testing loss: 0.005328810574220759 Test psnr22.937961052686596 dB\n",
      "Epoch 113. Training loss: 0.0038446013145802312 Train psnr 24.633543110327675 dB\n",
      "Epoch 113. Testing loss: 0.005504618332322154 Test psnr23.050473249212992 dB\n",
      "Epoch 114. Training loss: 0.003883052721472555 Train psnr 24.58090165913833 dB\n",
      "Epoch 114. Testing loss: 0.005063593670326684 Test psnr23.28875524680441 dB\n",
      "Epoch 115. Training loss: 0.003994692490730239 Train psnr 24.437928251010554 dB\n",
      "Epoch 115. Testing loss: 0.00441361464826124 Test psnr24.014656872282842 dB\n",
      "Epoch 116. Training loss: 0.00363839641846553 Train psnr 24.851730839912545 dB\n",
      "Epoch 116. Testing loss: 0.005378153807084475 Test psnr22.84147688986789 dB\n",
      "Epoch 117. Training loss: 0.0038149720895218485 Train psnr 24.611017202338736 dB\n",
      "Epoch 117. Testing loss: 0.004912188775571329 Test psnr23.573837648885448 dB\n",
      "Epoch 118. Training loss: 0.0038028285392404846 Train psnr 24.86576097971656 dB\n",
      "Epoch 118. Testing loss: 0.0051938046401898775 Test psnr23.456395686249973 dB\n",
      "Epoch 119. Training loss: 0.003796664722214796 Train psnr 24.576666529382663 dB\n",
      "Epoch 119. Testing loss: 0.004412203062591808 Test psnr23.743009720250644 dB\n",
      "Epoch 120. Training loss: 0.0037515405708466445 Train psnr 24.704519566133456 dB\n",
      "Epoch 120. Testing loss: 0.004599292130608644 Test psnr23.645403052935354 dB\n",
      "Epoch 121. Training loss: 0.004097726363525318 Train psnr 24.63504282206541 dB\n",
      "Epoch 121. Testing loss: 0.004606909617515547 Test psnr23.59302874328989 dB\n",
      "Epoch 122. Training loss: 0.0036124126074770302 Train psnr 24.85688342633948 dB\n",
      "Epoch 122. Testing loss: 0.005007285591480988 Test psnr23.357603257653818 dB\n",
      "Epoch 123. Training loss: 0.003880335920768087 Train psnr 24.371767313118188 dB\n",
      "Epoch 123. Testing loss: 0.0062662526366433925 Test psnr22.93095607479915 dB\n",
      "Epoch 124. Training loss: 0.0038046332835955056 Train psnr 24.708745077543778 dB\n",
      "Epoch 124. Testing loss: 0.004039668245241046 Test psnr24.17168215563142 dB\n",
      "Epoch 125. Training loss: 0.00398604387801402 Train psnr 24.390769591566755 dB\n",
      "Epoch 125. Testing loss: 0.005086409044452012 Test psnr23.412230781515575 dB\n",
      "Epoch 126. Training loss: 0.003702155255157043 Train psnr 24.852463682998767 dB\n",
      "Epoch 126. Testing loss: 0.004166390946401017 Test psnr23.8632414978618 dB\n",
      "Epoch 127. Training loss: 0.0038778653900392287 Train psnr 24.832511575143936 dB\n",
      "Epoch 127. Testing loss: 0.006107035924547485 Test psnr22.609728916058565 dB\n",
      "Epoch 128. Training loss: 0.003697874833290514 Train psnr 24.682766104432584 dB\n",
      "Epoch 128. Testing loss: 0.00557711284740695 Test psnr23.133666191127123 dB\n",
      "Epoch 129. Training loss: 0.003697829136191949 Train psnr 24.739898832819787 dB\n",
      "Epoch 129. Testing loss: 0.005019796014364276 Test psnr23.13759073283993 dB\n",
      "Epoch 130. Training loss: 0.004053098968589646 Train psnr 24.43669323814184 dB\n",
      "Epoch 130. Testing loss: 0.0037924825280372587 Test psnr24.393781324355707 dB\n",
      "Epoch 131. Training loss: 0.0037256829734695586 Train psnr 24.741052652354355 dB\n",
      "Epoch 131. Testing loss: 0.005900481981890542 Test psnr22.82071516056728 dB\n",
      "Epoch 132. Training loss: 0.0038332692081958315 Train psnr 24.465944664795867 dB\n",
      "Epoch 132. Testing loss: 0.0037410991000277655 Test psnr24.518059269043768 dB\n",
      "Epoch 133. Training loss: 0.003616786226956991 Train psnr 24.796964968048222 dB\n",
      "Epoch 133. Testing loss: 0.004855372311015215 Test psnr23.437577168461292 dB\n",
      "Epoch 134. Training loss: 0.0036072585151710533 Train psnr 24.929903016586547 dB\n",
      "Epoch 134. Testing loss: 0.005074833353449192 Test psnr23.151551788130572 dB\n",
      "Epoch 135. Training loss: 0.004104421296353011 Train psnr 24.478117497344105 dB\n",
      "Epoch 135. Testing loss: 0.005038746166974306 Test psnr23.146376832494035 dB\n",
      "Epoch 136. Training loss: 0.004018067470098143 Train psnr 24.478473830149213 dB\n",
      "Epoch 136. Testing loss: 0.00497188961266407 Test psnr23.29855001817207 dB\n",
      "Epoch 137. Training loss: 0.0040839691442159706 Train psnr 24.44778392944249 dB\n",
      "Epoch 137. Testing loss: 0.004225478208224688 Test psnr23.912459431961782 dB\n",
      "Epoch 138. Training loss: 0.0036174028360268524 Train psnr 24.804225209888493 dB\n",
      "Epoch 138. Testing loss: 0.005589614489248821 Test psnr23.372260113731738 dB\n",
      "Epoch 139. Training loss: 0.004016851387476842 Train psnr 24.399209739461313 dB\n",
      "Epoch 139. Testing loss: 0.005148717035938587 Test psnr23.08126444734767 dB\n",
      "Epoch 140. Training loss: 0.0037876126385016137 Train psnr 24.56591005500019 dB\n",
      "Epoch 140. Testing loss: 0.005390424281358719 Test psnr23.0455766088112 dB\n",
      "Epoch 141. Training loss: 0.00395058568673241 Train psnr 24.396695789511387 dB\n",
      "Epoch 141. Testing loss: 0.003762206495074289 Test psnr24.404723324385596 dB\n",
      "Epoch 142. Training loss: 0.003651272442208178 Train psnr 24.693369081784663 dB\n",
      "Epoch 142. Testing loss: 0.004113286234704512 Test psnr24.092050152135503 dB\n",
      "Epoch 143. Training loss: 0.00369548025079431 Train psnr 24.85061119174841 dB\n",
      "Epoch 143. Testing loss: 0.006353141706702965 Test psnr22.603387392261663 dB\n",
      "Epoch 144. Training loss: 0.003513339460161596 Train psnr 25.04232488435105 dB\n",
      "Epoch 144. Testing loss: 0.004152704878444118 Test psnr24.31236698622535 dB\n",
      "Epoch 145. Training loss: 0.003707833996598135 Train psnr 24.79638886519735 dB\n",
      "Epoch 145. Testing loss: 0.006163181271404028 Test psnr22.92188828128038 dB\n",
      "Epoch 146. Training loss: 0.003717355122748893 Train psnr 24.841225134097915 dB\n",
      "Epoch 146. Testing loss: 0.0038033854881567614 Test psnr24.46652766552457 dB\n",
      "Epoch 147. Training loss: 0.003931900931587606 Train psnr 24.559110623377716 dB\n",
      "Epoch 147. Testing loss: 0.005115477867158396 Test psnr23.37381970341576 dB\n",
      "Epoch 148. Training loss: 0.003720126966455657 Train psnr 24.750865353403107 dB\n",
      "Epoch 148. Testing loss: 0.0038099666126072407 Test psnr24.295292487262184 dB\n",
      "Epoch 149. Training loss: 0.0034999955719206156 Train psnr 25.012440162454535 dB\n",
      "Epoch 149. Testing loss: 0.004590755627889719 Test psnr23.829194840717037 dB\n",
      "Epoch 150. Training loss: 0.003717230514443496 Train psnr 24.732157449447776 dB\n",
      "Epoch 150. Testing loss: 0.004380246557827506 Test psnr23.917396058725988 dB\n",
      "Epoch 151. Training loss: 0.0035912598924417245 Train psnr 24.758672289009557 dB\n",
      "Epoch 151. Testing loss: 0.005063171365431377 Test psnr23.30818154135338 dB\n",
      "Epoch 152. Training loss: 0.003260993848558875 Train psnr 25.335085845259048 dB\n",
      "Epoch 152. Testing loss: 0.004916581491540585 Test psnr23.26194282321355 dB\n",
      "Epoch 153. Training loss: 0.0037741127317738638 Train psnr 24.65786277008963 dB\n",
      "Epoch 153. Testing loss: 0.003535205398553184 Test psnr24.599594634545024 dB\n",
      "Epoch 154. Training loss: 0.0035734219709411263 Train psnr 24.808176975981272 dB\n",
      "Epoch 154. Testing loss: 0.00428206441990499 Test psnr24.3668928678781 dB\n",
      "Epoch 155. Training loss: 0.0038145769473263307 Train psnr 24.57066105256138 dB\n",
      "Epoch 155. Testing loss: 0.0055196924534227166 Test psnr22.80213003569903 dB\n",
      "Epoch 156. Training loss: 0.0038025700099145374 Train psnr 24.55658383936471 dB\n",
      "Epoch 156. Testing loss: 0.004612931050360203 Test psnr23.829674789279782 dB\n",
      "Epoch 157. Training loss: 0.0038207006383393157 Train psnr 24.5803101309917 dB\n",
      "Epoch 157. Testing loss: 0.00454533429417227 Test psnr23.63706222203275 dB\n",
      "Epoch 158. Training loss: 0.0038027554268442224 Train psnr 24.646950281128102 dB\n",
      "Epoch 158. Testing loss: 0.0053016610244022945 Test psnr23.06845190364019 dB\n",
      "Epoch 159. Training loss: 0.0038266117687606694 Train psnr 24.586542964236774 dB\n",
      "Epoch 159. Testing loss: 0.004338514625227877 Test psnr23.897098993041627 dB\n",
      "Epoch 160. Training loss: 0.003564099599443899 Train psnr 24.907547872463 dB\n",
      "Epoch 160. Testing loss: 0.004487901460379362 Test psnr23.814676024865605 dB\n",
      "Epoch 161. Training loss: 0.003997264525918453 Train psnr 24.675636306213054 dB\n",
      "Epoch 161. Testing loss: 0.0041161206484373125 Test psnr24.786391063019494 dB\n",
      "Epoch 162. Training loss: 0.0037591262830813463 Train psnr 24.657523575654263 dB\n",
      "Epoch 162. Testing loss: 0.004710533822487507 Test psnr23.342937137467604 dB\n",
      "Epoch 163. Training loss: 0.003655791386814886 Train psnr 24.737196472490325 dB\n",
      "Epoch 163. Testing loss: 0.0048107389094574115 Test psnr23.301189166879762 dB\n",
      "Epoch 164. Training loss: 0.004051315402121921 Train psnr 24.38622330309869 dB\n",
      "Epoch 164. Testing loss: 0.005508410578061428 Test psnr23.046481507121126 dB\n",
      "Epoch 165. Training loss: 0.0035526232565181296 Train psnr 25.115847204645465 dB\n",
      "Epoch 165. Testing loss: 0.0038381021503092988 Test psnr24.675390783121447 dB\n",
      "Epoch 166. Training loss: 0.0036916445201393543 Train psnr 24.70007155623961 dB\n",
      "Epoch 166. Testing loss: 0.003989891315411244 Test psnr24.248115754558142 dB\n",
      "Epoch 167. Training loss: 0.003584585156651181 Train psnr 24.938299272912662 dB\n",
      "Epoch 167. Testing loss: 0.005980860940845949 Test psnr22.495810751826294 dB\n",
      "Epoch 168. Training loss: 0.003734336656379399 Train psnr 24.672135662909234 dB\n",
      "Epoch 168. Testing loss: 0.0044500624228801045 Test psnr23.773155951832912 dB\n",
      "Epoch 169. Training loss: 0.003749190343609243 Train psnr 24.55805818367553 dB\n",
      "Epoch 169. Testing loss: 0.0044911761901208335 Test psnr23.785491915956364 dB\n",
      "Epoch 170. Training loss: 0.003763355347409583 Train psnr 24.662963066756845 dB\n",
      "Epoch 170. Testing loss: 0.0050066804978996515 Test psnr23.2784524177278 dB\n",
      "Epoch 171. Training loss: 0.003610621780369496 Train psnr 24.792194092547433 dB\n",
      "Epoch 171. Testing loss: 0.004091176869613784 Test psnr24.078483539141043 dB\n",
      "Epoch 172. Training loss: 0.0036195209740023863 Train psnr 24.935941114367704 dB\n",
      "Epoch 172. Testing loss: 0.004257562703319958 Test psnr23.95341306764768 dB\n",
      "Epoch 173. Training loss: 0.004020032182891379 Train psnr 24.419647893759624 dB\n",
      "Epoch 173. Testing loss: 0.00418954502258982 Test psnr24.055619734568655 dB\n",
      "Epoch 174. Training loss: 0.003797303203068543 Train psnr 24.74332693536001 dB\n",
      "Epoch 174. Testing loss: 0.0041002735295998195 Test psnr23.96751379815012 dB\n",
      "Epoch 175. Training loss: 0.003782940021585346 Train psnr 24.696089723790678 dB\n",
      "Epoch 175. Testing loss: 0.004327102098613977 Test psnr23.73289248886388 dB\n",
      "Epoch 176. Training loss: 0.0035275507538595745 Train psnr 24.929234481763977 dB\n",
      "Epoch 176. Testing loss: 0.00473761442117393 Test psnr23.486324848648273 dB\n",
      "Epoch 177. Training loss: 0.003772097133230745 Train psnr 24.61418837210167 dB\n",
      "Epoch 177. Testing loss: 0.00495461407782776 Test psnr23.46604147094867 dB\n",
      "Epoch 178. Training loss: 0.0033398128110555965 Train psnr 25.15618558683341 dB\n",
      "Epoch 178. Testing loss: 0.0048898678672100815 Test psnr23.477989438679227 dB\n",
      "Epoch 179. Training loss: 0.0038892111369294292 Train psnr 24.493082377046676 dB\n",
      "Epoch 179. Testing loss: 0.004157461076309639 Test psnr24.521160635461886 dB\n",
      "Epoch 180. Training loss: 0.003566904267165483 Train psnr 24.80097833618541 dB\n",
      "Epoch 180. Testing loss: 0.004213073224361453 Test psnr23.972115641096998 dB\n",
      "Epoch 181. Training loss: 0.00367599615435067 Train psnr 24.826194994810578 dB\n",
      "Epoch 181. Testing loss: 0.0037673384815986666 Test psnr24.51072210654082 dB\n",
      "Epoch 182. Training loss: 0.003964800026120716 Train psnr 24.470668269290808 dB\n",
      "Epoch 182. Testing loss: 0.0044929515570402145 Test psnr23.749847947827643 dB\n",
      "Epoch 183. Training loss: 0.0037983968208560297 Train psnr 24.7350341754496 dB\n",
      "Epoch 183. Testing loss: 0.004115503846800753 Test psnr24.16823725024984 dB\n",
      "Epoch 184. Training loss: 0.0038260745748534405 Train psnr 24.811524014459845 dB\n",
      "Epoch 184. Testing loss: 0.0037585418405277388 Test psnr24.89874776648989 dB\n",
      "模型更新成功\n",
      "Epoch 185. Training loss: 0.003608817770758546 Train psnr 25.065728734164626 dB\n",
      "Epoch 185. Testing loss: 0.004428948275744915 Test psnr23.667627758641277 dB\n",
      "Epoch 186. Training loss: 0.003415841227315628 Train psnr 24.94813190781871 dB\n",
      "Epoch 186. Testing loss: 0.0049985259704824 Test psnr23.190839712843083 dB\n",
      "Epoch 187. Training loss: 0.003567560788309365 Train psnr 24.900330855023803 dB\n",
      "Epoch 187. Testing loss: 0.0057840295402067044 Test psnr22.784253875985815 dB\n",
      "Epoch 188. Training loss: 0.003929873368817202 Train psnr 24.33391075805456 dB\n",
      "Epoch 188. Testing loss: 0.003557963704224676 Test psnr25.271582676271976 dB\n",
      "模型更新成功\n",
      "Epoch 189. Training loss: 0.003401950428572794 Train psnr 25.010611720084228 dB\n",
      "Epoch 189. Testing loss: 0.005203728630606618 Test psnr23.046918071692826 dB\n",
      "Epoch 190. Training loss: 0.003907603450658682 Train psnr 24.472645578207207 dB\n",
      "Epoch 190. Testing loss: 0.004041940040354218 Test psnr24.226686062500097 dB\n",
      "Epoch 191. Training loss: 0.0036996844686208326 Train psnr 24.673448995727416 dB\n",
      "Epoch 191. Testing loss: 0.004859416579295482 Test psnr23.46999742463839 dB\n",
      "Epoch 192. Training loss: 0.0035454307421388335 Train psnr 24.872567194426587 dB\n",
      "Epoch 192. Testing loss: 0.00514289500590946 Test psnr23.102889237593242 dB\n",
      "Epoch 193. Training loss: 0.003636523846357146 Train psnr 24.910990425534163 dB\n",
      "Epoch 193. Testing loss: 0.005333140425916229 Test psnr22.848530723092985 dB\n",
      "Epoch 194. Training loss: 0.0033950238782716425 Train psnr 25.032565152784525 dB\n",
      "Epoch 194. Testing loss: 0.0045170604051756 Test psnr23.729421338724723 dB\n",
      "Epoch 195. Training loss: 0.00399152825079989 Train psnr 24.59103996670159 dB\n",
      "Epoch 195. Testing loss: 0.004055212318365063 Test psnr24.01022992611033 dB\n",
      "Epoch 196. Training loss: 0.003641837641082116 Train psnr 24.79341212438987 dB\n",
      "Epoch 196. Testing loss: 0.005515608238056302 Test psnr22.912871915074884 dB\n",
      "Epoch 197. Training loss: 0.003808992568673076 Train psnr 24.58533130330719 dB\n",
      "Epoch 197. Testing loss: 0.004194209135935775 Test psnr24.396160763848286 dB\n",
      "Epoch 198. Training loss: 0.003461065310515104 Train psnr 25.125476975887064 dB\n",
      "Epoch 198. Testing loss: 0.005315630330837199 Test psnr23.16167301537625 dB\n",
      "Epoch 199. Training loss: 0.0038463896836905755 Train psnr 24.516995463926467 dB\n",
      "Epoch 199. Testing loss: 0.0042966435264263836 Test psnr24.05439929061803 dB\n",
      "Epoch 200. Training loss: 0.003935766032092241 Train psnr 24.46548693414509 dB\n",
      "Epoch 200. Testing loss: 0.005685394230697837 Test psnr22.72823088391196 dB\n",
      "Epoch 201. Training loss: 0.0038867350116274075 Train psnr 24.736613229779362 dB\n",
      "Epoch 201. Testing loss: 0.005013137889493789 Test psnr23.35309963827339 dB\n",
      "Epoch 202. Training loss: 0.003899415628167621 Train psnr 24.598178234716144 dB\n",
      "Epoch 202. Testing loss: 0.004593799256586603 Test psnr23.713886764842403 dB\n",
      "Epoch 203. Training loss: 0.003651206969822708 Train psnr 24.746291975847047 dB\n",
      "Epoch 203. Testing loss: 0.004506575209753854 Test psnr23.757012266942173 dB\n",
      "Epoch 204. Training loss: 0.0037068968011768895 Train psnr 24.794152365622956 dB\n",
      "Epoch 204. Testing loss: 0.005581133965668934 Test psnr22.654115209176094 dB\n",
      "Epoch 205. Training loss: 0.003436490324562775 Train psnr 25.116076577202787 dB\n",
      "Epoch 205. Testing loss: 0.004597731699634876 Test psnr23.595031085554414 dB\n",
      "Epoch 206. Training loss: 0.0032961172023134536 Train psnr 25.203584420073597 dB\n",
      "Epoch 206. Testing loss: 0.00398715612079416 Test psnr24.16353049029896 dB\n",
      "Epoch 207. Training loss: 0.003785592187277711 Train psnr 24.645887681374287 dB\n",
      "Epoch 207. Testing loss: 0.005084809015638062 Test psnr23.101718650300274 dB\n",
      "Epoch 208. Training loss: 0.0037671402295879823 Train psnr 24.8369482666229 dB\n",
      "Epoch 208. Testing loss: 0.004509468845623944 Test psnr24.13056063667049 dB\n",
      "Epoch 209. Training loss: 0.0034574497860791 Train psnr 25.319319453854728 dB\n",
      "Epoch 209. Testing loss: 0.0034658892545849085 Test psnr24.78762009355903 dB\n",
      "Epoch 210. Training loss: 0.00339469748749316 Train psnr 25.101675680141916 dB\n",
      "Epoch 210. Testing loss: 0.0036821500065603425 Test psnr24.571044200579546 dB\n",
      "Epoch 211. Training loss: 0.0037839699847002826 Train psnr 24.66683396150113 dB\n",
      "Epoch 211. Testing loss: 0.004518221830949187 Test psnr23.74533073778016 dB\n",
      "Epoch 212. Training loss: 0.0041977774245631795 Train psnr 24.592583597433674 dB\n",
      "Epoch 212. Testing loss: 0.004640902958012053 Test psnr23.66548255500453 dB\n",
      "Epoch 213. Training loss: 0.003945570336981562 Train psnr 24.558717125856926 dB\n",
      "Epoch 213. Testing loss: 0.004819600809631603 Test psnr23.70888009815788 dB\n",
      "Epoch 214. Training loss: 0.003316455133404305 Train psnr 25.428590769297955 dB\n",
      "Epoch 214. Testing loss: 0.004897435694666845 Test psnr23.269922621029878 dB\n",
      "Epoch 215. Training loss: 0.003664744229529772 Train psnr 24.69924828702159 dB\n",
      "Epoch 215. Testing loss: 0.0038782391431076185 Test psnr24.38502844445848 dB\n",
      "Epoch 216. Training loss: 0.0038294429286268718 Train psnr 24.586295089846733 dB\n",
      "Epoch 216. Testing loss: 0.004864307519580636 Test psnr23.4635807061096 dB\n",
      "Epoch 217. Training loss: 0.0034859868766241625 Train psnr 25.271919887023703 dB\n",
      "Epoch 217. Testing loss: 0.005847531204511013 Test psnr22.63992467875056 dB\n",
      "Epoch 218. Training loss: 0.003891022544019251 Train psnr 24.596466407031457 dB\n",
      "Epoch 218. Testing loss: 0.004425402231780546 Test psnr23.63131478617021 dB\n",
      "Epoch 219. Training loss: 0.0037533477553280824 Train psnr 24.59696733322026 dB\n",
      "Epoch 219. Testing loss: 0.004782210869182434 Test psnr23.588985141702274 dB\n",
      "Epoch 220. Training loss: 0.003401742730363223 Train psnr 25.40580384893817 dB\n",
      "Epoch 220. Testing loss: 0.0042346379653151545 Test psnr23.935150857544606 dB\n",
      "Epoch 221. Training loss: 0.003433341920179756 Train psnr 25.05043696360096 dB\n",
      "Epoch 221. Testing loss: 0.004646076488175562 Test psnr23.365899923169952 dB\n",
      "Epoch 222. Training loss: 0.0036814278543093487 Train psnr 24.76190062240826 dB\n",
      "Epoch 222. Testing loss: 0.004694325450275626 Test psnr23.45327574920515 dB\n",
      "Epoch 223. Training loss: 0.003668184300247384 Train psnr 24.818098510631636 dB\n",
      "Epoch 223. Testing loss: 0.004346892171140228 Test psnr23.76856037651545 dB\n",
      "Epoch 224. Training loss: 0.003759507522836589 Train psnr 24.90924570265404 dB\n",
      "Epoch 224. Testing loss: 0.005435554011325751 Test psnr22.89929760639793 dB\n",
      "Epoch 225. Training loss: 0.0035592990032838365 Train psnr 24.82829248335267 dB\n",
      "Epoch 225. Testing loss: 0.003952093721766557 Test psnr24.263957016306087 dB\n",
      "Epoch 226. Training loss: 0.003809305473655593 Train psnr 24.628293542988374 dB\n",
      "Epoch 226. Testing loss: 0.00595450634136796 Test psnr22.652442378588578 dB\n",
      "Epoch 227. Training loss: 0.0036961594616928906 Train psnr 24.850088181784038 dB\n",
      "Epoch 227. Testing loss: 0.004788305909772005 Test psnr23.366988671166222 dB\n",
      "Epoch 228. Training loss: 0.0037132889816635533 Train psnr 24.802034014446498 dB\n",
      "Epoch 228. Testing loss: 0.0049407505762896365 Test psnr23.286316454835134 dB\n",
      "Epoch 229. Training loss: 0.0039029181444723356 Train psnr 24.448133939493417 dB\n",
      "Epoch 229. Testing loss: 0.004634747680808816 Test psnr23.513427158529936 dB\n",
      "Epoch 230. Training loss: 0.00310994081072542 Train psnr 25.41166846715619 dB\n",
      "Epoch 230. Testing loss: 0.004146563454664179 Test psnr24.029958171495828 dB\n",
      "Epoch 231. Training loss: 0.003470546660920311 Train psnr 25.172866102913144 dB\n",
      "Epoch 231. Testing loss: 0.004745751918692674 Test psnr23.468547622626122 dB\n",
      "Epoch 232. Training loss: 0.0034121864663208263 Train psnr 25.237116910691846 dB\n",
      "Epoch 232. Testing loss: 0.004657346954835313 Test psnr23.432746193362753 dB\n",
      "Epoch 233. Training loss: 0.003871454637734579 Train psnr 24.520916337141323 dB\n",
      "Epoch 233. Testing loss: 0.004130096174776554 Test psnr24.383373274011582 dB\n",
      "Epoch 234. Training loss: 0.004154401112413197 Train psnr 24.29382182308144 dB\n",
      "Epoch 234. Testing loss: 0.004720380795853478 Test psnr23.528187245282535 dB\n",
      "Epoch 235. Training loss: 0.003445040742997407 Train psnr 25.1626350704311 dB\n",
      "Epoch 235. Testing loss: 0.004806589601295335 Test psnr23.959608696623828 dB\n",
      "Epoch 236. Training loss: 0.003657642475190458 Train psnr 24.789542831455165 dB\n",
      "Epoch 236. Testing loss: 0.0043037699402443 Test psnr23.80969901798746 dB\n",
      "Epoch 237. Training loss: 0.0038056856290878435 Train psnr 24.75511541830321 dB\n",
      "Epoch 237. Testing loss: 0.004955408130107182 Test psnr23.114718083137955 dB\n",
      "Epoch 238. Training loss: 0.003682126615833687 Train psnr 24.830148536070503 dB\n",
      "Epoch 238. Testing loss: 0.004682318939428244 Test psnr23.717871537904987 dB\n",
      "Epoch 239. Training loss: 0.003853500547018229 Train psnr 24.588805232124113 dB\n",
      "Epoch 239. Testing loss: 0.004796573725928154 Test psnr23.739557879847187 dB\n",
      "Epoch 240. Training loss: 0.0034290835048938007 Train psnr 25.074576130134247 dB\n",
      "Epoch 240. Testing loss: 0.003950629948771426 Test psnr24.383788634339673 dB\n",
      "Epoch 241. Training loss: 0.003590123819824504 Train psnr 24.85098433091009 dB\n",
      "Epoch 241. Testing loss: 0.00437075860931405 Test psnr23.858498643119052 dB\n",
      "Epoch 242. Training loss: 0.0037421674721388213 Train psnr 24.861525877976334 dB\n",
      "Epoch 242. Testing loss: 0.0058413824798273185 Test psnr22.737788158716473 dB\n",
      "Epoch 243. Training loss: 0.003341248036329553 Train psnr 25.228558532489043 dB\n",
      "Epoch 243. Testing loss: 0.004332132271624037 Test psnr23.748822662017695 dB\n",
      "Epoch 244. Training loss: 0.0036160733607973447 Train psnr 24.904680070227187 dB\n",
      "Epoch 244. Testing loss: 0.004079249754015889 Test psnr24.09149723361846 dB\n",
      "Epoch 245. Training loss: 0.003682119547177041 Train psnr 24.628653288944992 dB\n",
      "Epoch 245. Testing loss: 0.004061134864709207 Test psnr24.215899190243135 dB\n",
      "Epoch 246. Training loss: 0.0037481630029026092 Train psnr 24.654936068456458 dB\n",
      "Epoch 246. Testing loss: 0.003766286901996604 Test psnr24.94181150228831 dB\n",
      "Epoch 247. Training loss: 0.0035801117855794075 Train psnr 24.973188190121935 dB\n",
      "Epoch 247. Testing loss: 0.004434355168736407 Test psnr23.597482982144705 dB\n",
      "Epoch 248. Training loss: 0.0034990751433692743 Train psnr 25.145587824788084 dB\n",
      "Epoch 248. Testing loss: 0.004608983107443366 Test psnr23.738118165032972 dB\n",
      "Epoch 249. Training loss: 0.0037123419083001322 Train psnr 24.721968867597624 dB\n",
      "Epoch 249. Testing loss: 0.005630603725356715 Test psnr22.80434052096057 dB\n",
      "Epoch 250. Training loss: 0.0036121522129529664 Train psnr 24.83426192404341 dB\n",
      "Epoch 250. Testing loss: 0.004810345791546362 Test psnr23.42466630779909 dB\n",
      "Epoch 251. Training loss: 0.003831760761769194 Train psnr 24.455515543392252 dB\n",
      "Epoch 251. Testing loss: 0.003761799939508949 Test psnr24.447275752724515 dB\n",
      "Epoch 252. Training loss: 0.003573174032856498 Train psnr 24.890924647889534 dB\n",
      "Epoch 252. Testing loss: 0.005259009344237191 Test psnr23.26377118042945 dB\n",
      "Epoch 253. Training loss: 0.0038756136578229957 Train psnr 24.597811722099316 dB\n",
      "Epoch 253. Testing loss: 0.004063356102311185 Test psnr24.274694823939182 dB\n",
      "Epoch 254. Training loss: 0.003526175251177496 Train psnr 24.90700775755048 dB\n",
      "Epoch 254. Testing loss: 0.005089332715475133 Test psnr23.165458586935493 dB\n",
      "Epoch 255. Training loss: 0.0036254724642882743 Train psnr 24.820570036417966 dB\n",
      "Epoch 255. Testing loss: 0.005480357512299504 Test psnr23.083984875261315 dB\n",
      "Epoch 256. Training loss: 0.0035508001884935717 Train psnr 24.96988053192191 dB\n",
      "Epoch 256. Testing loss: 0.0037960094798888478 Test psnr24.4668007836313 dB\n",
      "Epoch 257. Training loss: 0.0036035232233667842 Train psnr 24.76544935578497 dB\n",
      "Epoch 257. Testing loss: 0.00481762138328382 Test psnr23.416249125002572 dB\n",
      "Epoch 258. Training loss: 0.0034004373541265203 Train psnr 24.949416630352815 dB\n",
      "Epoch 258. Testing loss: 0.004005016492945808 Test psnr24.208092937186656 dB\n",
      "Epoch 259. Training loss: 0.0036832845030483185 Train psnr 24.862184939321704 dB\n",
      "Epoch 259. Testing loss: 0.004920344001480511 Test psnr23.35193088927635 dB\n",
      "Epoch 260. Training loss: 0.003632931620813906 Train psnr 24.790814058034623 dB\n",
      "Epoch 260. Testing loss: 0.004940504673868418 Test psnr23.38627848184109 dB\n",
      "Epoch 261. Training loss: 0.003680560537695623 Train psnr 24.755912408908596 dB\n",
      "Epoch 261. Testing loss: 0.0057545840141496486 Test psnr22.80630781127321 dB\n",
      "Epoch 262. Training loss: 0.003976853923839435 Train psnr 24.454996440935204 dB\n",
      "Epoch 262. Testing loss: 0.004229271385286536 Test psnr24.067746188221104 dB\n",
      "Epoch 263. Training loss: 0.0035598923333740808 Train psnr 24.89381531349091 dB\n",
      "Epoch 263. Testing loss: 0.007149091655654567 Test psnr21.900815320817223 dB\n",
      "Epoch 264. Training loss: 0.003542476139652232 Train psnr 24.876760009032107 dB\n",
      "Epoch 264. Testing loss: 0.00534986934092428 Test psnr23.0309345439663 dB\n",
      "Epoch 265. Training loss: 0.0036700786338514533 Train psnr 24.738092645780053 dB\n",
      "Epoch 265. Testing loss: 0.004178755783608982 Test psnr24.101008982916767 dB\n",
      "Epoch 266. Training loss: 0.0035662574567444003 Train psnr 25.030134174141068 dB\n",
      "Epoch 266. Testing loss: 0.004424085507967642 Test psnr23.734702666918107 dB\n",
      "Epoch 267. Training loss: 0.0034315238549504756 Train psnr 25.139359202837348 dB\n",
      "Epoch 267. Testing loss: 0.004282963412281658 Test psnr24.266678335647203 dB\n",
      "Epoch 268. Training loss: 0.003978567347012199 Train psnr 24.484274118998496 dB\n",
      "Epoch 268. Testing loss: 0.004596612183377147 Test psnr23.597252395623265 dB\n",
      "Epoch 269. Training loss: 0.00363712522850715 Train psnr 24.758116792478667 dB\n",
      "Epoch 269. Testing loss: 0.0048840635323098725 Test psnr23.33462265256365 dB\n",
      "Epoch 270. Training loss: 0.003778611949089457 Train psnr 24.678686690405023 dB\n",
      "Epoch 270. Testing loss: 0.0030128910106473734 Test psnr25.495119948977155 dB\n",
      "模型更新成功\n",
      "Epoch 271. Training loss: 0.003753773874211076 Train psnr 24.71494687487629 dB\n",
      "Epoch 271. Testing loss: 0.003184759523719549 Test psnr25.11036678087632 dB\n",
      "Epoch 272. Training loss: 0.00350675530212915 Train psnr 25.11053104656347 dB\n",
      "Epoch 272. Testing loss: 0.005017825452211712 Test psnr23.395352906183422 dB\n",
      "Epoch 273. Training loss: 0.0035668663995079043 Train psnr 24.8727294011075 dB\n",
      "Epoch 273. Testing loss: 0.004588968286822949 Test psnr23.55817441169341 dB\n",
      "Epoch 274. Training loss: 0.003484939118814573 Train psnr 24.9298862997078 dB\n",
      "Epoch 274. Testing loss: 0.006008921257619347 Test psnr22.888892840932836 dB\n",
      "Epoch 275. Training loss: 0.003598846858694104 Train psnr 24.83915609401747 dB\n",
      "Epoch 275. Testing loss: 0.005797550381560411 Test psnr22.80876644377933 dB\n",
      "Epoch 276. Training loss: 0.0037550768639336815 Train psnr 24.952565783984014 dB\n",
      "Epoch 276. Testing loss: 0.004292064146803958 Test psnr23.94675455338413 dB\n",
      "Epoch 277. Training loss: 0.0037136991393932127 Train psnr 24.719184658728338 dB\n",
      "Epoch 277. Testing loss: 0.005110741925558874 Test psnr23.189020567348706 dB\n",
      "Epoch 278. Training loss: 0.0034434583667142873 Train psnr 25.14829188522502 dB\n",
      "Epoch 278. Testing loss: 0.005330904819337385 Test psnr23.29882102216769 dB\n",
      "Epoch 279. Training loss: 0.0037315125912101123 Train psnr 24.73069451217702 dB\n",
      "Epoch 279. Testing loss: 0.005083639740145632 Test psnr23.099054004099134 dB\n",
      "Epoch 280. Training loss: 0.003556672838034533 Train psnr 25.04837954356904 dB\n",
      "Epoch 280. Testing loss: 0.004735504310312015 Test psnr23.584924893623953 dB\n",
      "Epoch 281. Training loss: 0.003990798183765851 Train psnr 24.383115754547788 dB\n",
      "Epoch 281. Testing loss: 0.0049346675098474535 Test psnr23.46244365923289 dB\n",
      "Epoch 282. Training loss: 0.0035266811048546643 Train psnr 24.842435979428462 dB\n",
      "Epoch 282. Testing loss: 0.003941736217322094 Test psnr24.072413673215213 dB\n",
      "Epoch 283. Training loss: 0.00344539031165799 Train psnr 25.110685744166005 dB\n",
      "Epoch 283. Testing loss: 0.00435505883901247 Test psnr23.83581969354976 dB\n",
      "Epoch 284. Training loss: 0.003661168007519129 Train psnr 24.99790831217231 dB\n",
      "Epoch 284. Testing loss: 0.004026106059817331 Test psnr23.979584380910687 dB\n",
      "Epoch 285. Training loss: 0.003900072981578935 Train psnr 24.443007519006695 dB\n",
      "Epoch 285. Testing loss: 0.005509595719299146 Test psnr22.80977128408707 dB\n",
      "Epoch 286. Training loss: 0.0037760994235756236 Train psnr 24.738170867721756 dB\n",
      "Epoch 286. Testing loss: 0.005258056800812483 Test psnr23.101171947438996 dB\n",
      "Epoch 287. Training loss: 0.004011579473674493 Train psnr 24.399273059201235 dB\n",
      "Epoch 287. Testing loss: 0.005685689676153872 Test psnr23.646857151534448 dB\n",
      "Epoch 288. Training loss: 0.003636679207710059 Train psnr 24.744575655917476 dB\n",
      "Epoch 288. Testing loss: 0.004496197449043393 Test psnr23.80522932409968 dB\n",
      "Epoch 289. Training loss: 0.003766301647645601 Train psnr 24.768146302514722 dB\n",
      "Epoch 289. Testing loss: 0.004801495798996517 Test psnr23.450132648966182 dB\n",
      "Epoch 290. Training loss: 0.0035179766924365572 Train psnr 25.070794854802145 dB\n",
      "Epoch 290. Testing loss: 0.0038626748802406447 Test psnr24.356297058178267 dB\n",
      "Epoch 291. Training loss: 0.0035784492747073897 Train psnr 24.889726180092424 dB\n",
      "Epoch 291. Testing loss: 0.004084020719996521 Test psnr24.029652290029137 dB\n",
      "Epoch 292. Training loss: 0.0035861681313499026 Train psnr 24.957838269790393 dB\n",
      "Epoch 292. Testing loss: 0.0037934445343645556 Test psnr24.7403536733778 dB\n",
      "Epoch 293. Training loss: 0.003590863937381328 Train psnr 24.882522028269918 dB\n",
      "Epoch 293. Testing loss: 0.004613555868023208 Test psnr23.529536638698108 dB\n",
      "Epoch 294. Training loss: 0.0033319854696297595 Train psnr 25.175501667842376 dB\n",
      "Epoch 294. Testing loss: 0.0038940288026684095 Test psnr24.739072417676237 dB\n",
      "Epoch 295. Training loss: 0.003488242913143742 Train psnr 24.943106043607834 dB\n",
      "Epoch 295. Testing loss: 0.004387139076633113 Test psnr24.036084379598968 dB\n",
      "Epoch 296. Training loss: 0.0038121623791786924 Train psnr 24.737870071008405 dB\n",
      "Epoch 296. Testing loss: 0.0047926398858960184 Test psnr23.353783882010465 dB\n",
      "Epoch 297. Training loss: 0.003424866300631772 Train psnr 24.97402540809973 dB\n",
      "Epoch 297. Testing loss: 0.005511370986433966 Test psnr22.90129690063713 dB\n",
      "Epoch 298. Training loss: 0.003707844339180411 Train psnr 24.73967040244709 dB\n",
      "Epoch 298. Testing loss: 0.00415819204811539 Test psnr24.18578499791577 dB\n",
      "Epoch 299. Training loss: 0.0036202113577083013 Train psnr 24.88828220649206 dB\n",
      "Epoch 299. Testing loss: 0.006180298182048968 Test psnr22.439401093963987 dB\n",
      "Epoch 300. Training loss: 0.0033235003387457446 Train psnr 25.13159688314379 dB\n",
      "Epoch 300. Testing loss: 0.006243914332506912 Test psnr22.895777782453056 dB\n",
      "Epoch 301. Training loss: 0.0036240042281222708 Train psnr 24.958048981321095 dB\n",
      "Epoch 301. Testing loss: 0.0040235539366092 Test psnr24.042547407495622 dB\n",
      "Epoch 302. Training loss: 0.0037399131698501215 Train psnr 24.66009271193728 dB\n",
      "Epoch 302. Testing loss: 0.005661283020994493 Test psnr23.03150148146812 dB\n",
      "Epoch 303. Training loss: 0.003411950649726286 Train psnr 24.977109819192936 dB\n",
      "Epoch 303. Testing loss: 0.004591892007738352 Test psnr23.73432139138347 dB\n",
      "Epoch 304. Training loss: 0.003578253422267408 Train psnr 24.73631028176649 dB\n",
      "Epoch 304. Testing loss: 0.004637758946046233 Test psnr23.643380044208723 dB\n",
      "Epoch 305. Training loss: 0.0037203842892491244 Train psnr 24.912088383395396 dB\n",
      "Epoch 305. Testing loss: 0.0042953696101903915 Test psnr23.85806915648263 dB\n",
      "Epoch 306. Training loss: 0.003506080828517218 Train psnr 25.064060451891148 dB\n",
      "Epoch 306. Testing loss: 0.004241887080882277 Test psnr24.185028132415226 dB\n",
      "Epoch 307. Training loss: 0.003524429590661863 Train psnr 24.90393827507399 dB\n",
      "Epoch 307. Testing loss: 0.004661236523783633 Test psnr23.61985008336208 dB\n",
      "Epoch 308. Training loss: 0.0032658433754062443 Train psnr 25.197378946929113 dB\n",
      "Epoch 308. Testing loss: 0.003659870641838227 Test psnr24.919063718209152 dB\n",
      "Epoch 309. Training loss: 0.003528371114251122 Train psnr 25.08089871226481 dB\n",
      "Epoch 309. Testing loss: 0.0038886553208742824 Test psnr24.34251555082948 dB\n",
      "Epoch 310. Training loss: 0.003486853946621219 Train psnr 25.105357279813727 dB\n",
      "Epoch 310. Testing loss: 0.0039019870538530605 Test psnr24.409331658853574 dB\n",
      "Epoch 311. Training loss: 0.0035222822661397225 Train psnr 25.02637037601119 dB\n",
      "Epoch 311. Testing loss: 0.004804549422780318 Test psnr23.828636621678406 dB\n",
      "Epoch 312. Training loss: 0.0038425280822833117 Train psnr 24.618059704741288 dB\n",
      "Epoch 312. Testing loss: 0.0038672315422445536 Test psnr24.389702025680815 dB\n",
      "Epoch 313. Training loss: 0.0036671797994099428 Train psnr 24.73859757657715 dB\n",
      "Epoch 313. Testing loss: 0.005221498398376363 Test psnr23.026898608191768 dB\n",
      "Epoch 314. Training loss: 0.0034710694402619673 Train psnr 25.06742426818321 dB\n",
      "Epoch 314. Testing loss: 0.004334687388369015 Test psnr23.9082494801707 dB\n",
      "Epoch 315. Training loss: 0.0035313329058944396 Train psnr 24.86890994813945 dB\n",
      "Epoch 315. Testing loss: 0.004889371272708688 Test psnr23.34697645426838 dB\n",
      "Epoch 316. Training loss: 0.00338595391612647 Train psnr 25.27786452904574 dB\n",
      "Epoch 316. Testing loss: 0.005531243780361754 Test psnr22.88052133793395 dB\n",
      "Epoch 317. Training loss: 0.0035490484462985606 Train psnr 24.861629530753888 dB\n",
      "Epoch 317. Testing loss: 0.004186670445570988 Test psnr24.383626084576747 dB\n",
      "Epoch 318. Training loss: 0.0031946460030188688 Train psnr 25.49943089824724 dB\n",
      "Epoch 318. Testing loss: 0.004475146997720003 Test psnr23.92907537346039 dB\n",
      "Epoch 319. Training loss: 0.00369412635183452 Train psnr 24.92701963069404 dB\n",
      "Epoch 319. Testing loss: 0.004054449232561248 Test psnr24.190082804796514 dB\n",
      "Epoch 320. Training loss: 0.003449403699242363 Train psnr 25.059180097365708 dB\n",
      "Epoch 320. Testing loss: 0.004306060893993292 Test psnr23.74176406931601 dB\n",
      "Epoch 321. Training loss: 0.003833325003812972 Train psnr 24.81644159792514 dB\n",
      "Epoch 321. Testing loss: 0.005178350057186825 Test psnr23.110465275259493 dB\n",
      "Epoch 322. Training loss: 0.0037103596086238036 Train psnr 24.82412048212097 dB\n",
      "Epoch 322. Testing loss: 0.004644160275347531 Test psnr23.754284828466968 dB\n",
      "Epoch 323. Training loss: 0.003534744520214174 Train psnr 24.96478192833748 dB\n",
      "Epoch 323. Testing loss: 0.004664585726069552 Test psnr23.555476926887533 dB\n",
      "Epoch 324. Training loss: 0.0036484500885483597 Train psnr 24.808388454915974 dB\n",
      "Epoch 324. Testing loss: 0.0048713206113981345 Test psnr23.43068382500611 dB\n",
      "Epoch 325. Training loss: 0.00356851558184676 Train psnr 24.84733206992414 dB\n",
      "Epoch 325. Testing loss: 0.004874087470982756 Test psnr23.43106588636176 dB\n",
      "Epoch 326. Training loss: 0.00385628029573382 Train psnr 24.627024547018785 dB\n",
      "Epoch 326. Testing loss: 0.005003510375640222 Test psnr23.30217617687573 dB\n",
      "Epoch 327. Training loss: 0.00357548152137417 Train psnr 24.84793627549011 dB\n",
      "Epoch 327. Testing loss: 0.004709542163514665 Test psnr23.50667936718018 dB\n",
      "Epoch 328. Training loss: 0.0036828375376532214 Train psnr 24.754291296851417 dB\n",
      "Epoch 328. Testing loss: 0.004306325356342963 Test psnr23.8015379228875 dB\n",
      "Epoch 329. Training loss: 0.0034485705423560973 Train psnr 25.082947628506243 dB\n",
      "Epoch 329. Testing loss: 0.0058803007871444735 Test psnr22.456609102543002 dB\n",
      "Epoch 330. Training loss: 0.003963425579856624 Train psnr 24.304424267799302 dB\n",
      "Epoch 330. Testing loss: 0.004010712495073676 Test psnr24.18423347410546 dB\n",
      "Epoch 331. Training loss: 0.0036801715573426663 Train psnr 24.745790868715616 dB\n",
      "Epoch 331. Testing loss: 0.0044045039851750645 Test psnr23.895329907280388 dB\n",
      "Epoch 332. Training loss: 0.0035611886159402496 Train psnr 24.961743944439146 dB\n",
      "Epoch 332. Testing loss: 0.004974729514547757 Test psnr23.26992131787509 dB\n",
      "Epoch 333. Training loss: 0.0034862563459268003 Train psnr 24.91125957402231 dB\n",
      "Epoch 333. Testing loss: 0.0047695463124130455 Test psnr23.451074264684856 dB\n",
      "Epoch 334. Training loss: 0.003747223959132833 Train psnr 24.821934741633736 dB\n",
      "Epoch 334. Testing loss: 0.0042183012368955785 Test psnr23.864021674533223 dB\n",
      "Epoch 335. Training loss: 0.003752919138621604 Train psnr 24.636928608344572 dB\n",
      "Epoch 335. Testing loss: 0.00463826595140355 Test psnr23.837779950511848 dB\n",
      "Epoch 336. Training loss: 0.003283637987854155 Train psnr 25.371798119163525 dB\n",
      "Epoch 336. Testing loss: 0.00576112382779164 Test psnr23.014479810718264 dB\n",
      "Epoch 337. Training loss: 0.00335104397922885 Train psnr 25.132482139743974 dB\n",
      "Epoch 337. Testing loss: 0.004619453800842166 Test psnr23.49480657509859 dB\n",
      "Epoch 338. Training loss: 0.0037150984229683353 Train psnr 24.78555835101948 dB\n",
      "Epoch 338. Testing loss: 0.004003301163070968 Test psnr24.327689095139966 dB\n",
      "Epoch 339. Training loss: 0.003365504915883209 Train psnr 25.3072217702782 dB\n",
      "Epoch 339. Testing loss: 0.004446538198473198 Test psnr24.065183318375354 dB\n",
      "Epoch 340. Training loss: 0.003458875789012956 Train psnr 25.12850428329496 dB\n",
      "Epoch 340. Testing loss: 0.005051550222560763 Test psnr23.59359891283251 dB\n",
      "Epoch 341. Training loss: 0.0034765839564466945 Train psnr 24.955576506734108 dB\n",
      "Epoch 341. Testing loss: 0.0037228272496057408 Test psnr24.415212418739337 dB\n",
      "Epoch 342. Training loss: 0.003459565839811898 Train psnr 25.06502558986986 dB\n",
      "Epoch 342. Testing loss: 0.004249562243265765 Test psnr24.17000027548088 dB\n",
      "Epoch 343. Training loss: 0.0031337600059423336 Train psnr 25.416511873558974 dB\n",
      "Epoch 343. Testing loss: 0.005721973987030131 Test psnr22.795409000024442 dB\n",
      "Epoch 344. Training loss: 0.003742197538693354 Train psnr 24.829086206716134 dB\n",
      "Epoch 344. Testing loss: 0.004725311217563493 Test psnr23.810316017842627 dB\n",
      "Epoch 345. Training loss: 0.0036559843207023255 Train psnr 24.810315550857013 dB\n",
      "Epoch 345. Testing loss: 0.004189306870102882 Test psnr24.147179940781797 dB\n",
      "Epoch 346. Training loss: 0.0037253941552256023 Train psnr 24.84042795865037 dB\n",
      "Epoch 346. Testing loss: 0.005111744328002844 Test psnr23.076666126643932 dB\n",
      "Epoch 347. Training loss: 0.0037194764519339067 Train psnr 24.7501569995099 dB\n",
      "Epoch 347. Testing loss: 0.00583796263007181 Test psnr23.022656706569677 dB\n",
      "Epoch 348. Training loss: 0.003544839213422516 Train psnr 24.974880196977782 dB\n",
      "Epoch 348. Testing loss: 0.005932454285877091 Test psnr22.9508700835823 dB\n",
      "Epoch 349. Training loss: 0.003555563668589712 Train psnr 24.80944198762436 dB\n",
      "Epoch 349. Testing loss: 0.004133505746722221 Test psnr24.00727176637542 dB\n",
      "Epoch 350. Training loss: 0.0035785475323025727 Train psnr 25.02592999756201 dB\n",
      "Epoch 350. Testing loss: 0.004295582251091089 Test psnr23.85718259114936 dB\n",
      "Epoch 351. Training loss: 0.0036772444084482757 Train psnr 24.853366410156436 dB\n",
      "Epoch 351. Testing loss: 0.004662588870685015 Test psnr23.462472816388757 dB\n",
      "Epoch 352. Training loss: 0.0033229476406663786 Train psnr 25.295579333571798 dB\n",
      "Epoch 352. Testing loss: 0.004865268611216119 Test psnr23.480255570975935 dB\n",
      "Epoch 353. Training loss: 0.0037293468230289585 Train psnr 24.687618737801476 dB\n",
      "Epoch 353. Testing loss: 0.0044106409851727745 Test psnr24.070738612114674 dB\n",
      "Epoch 354. Training loss: 0.003787768150990208 Train psnr 24.733414053595464 dB\n",
      "Epoch 354. Testing loss: 0.0031807112307952984 Test psnr25.17088292689197 dB\n",
      "Epoch 355. Training loss: 0.0034263938498936527 Train psnr 25.18902230024986 dB\n",
      "Epoch 355. Testing loss: 0.005049876103709851 Test psnr23.024537066021328 dB\n",
      "Epoch 356. Training loss: 0.003692855670427283 Train psnr 24.743965498110757 dB\n",
      "Epoch 356. Testing loss: 0.004158801964617201 Test psnr23.94160487707476 dB\n",
      "Epoch 357. Training loss: 0.003845729152345213 Train psnr 24.681119824187824 dB\n",
      "Epoch 357. Testing loss: 0.004635591758415103 Test psnr23.459880988642595 dB\n",
      "Epoch 358. Training loss: 0.0032933961432590557 Train psnr 25.23535945981764 dB\n",
      "Epoch 358. Testing loss: 0.004988953171830092 Test psnr23.497166345140858 dB\n",
      "Epoch 359. Training loss: 0.0035454924157085387 Train psnr 24.981041111159204 dB\n",
      "Epoch 359. Testing loss: 0.004586757692907538 Test psnr23.41880762971631 dB\n",
      "Epoch 360. Training loss: 0.003551126490428782 Train psnr 24.886756693881633 dB\n",
      "Epoch 360. Testing loss: 0.0062122035305947065 Test psnr23.011835355040013 dB\n",
      "Epoch 361. Training loss: 0.0033007017418480757 Train psnr 25.306007217540888 dB\n",
      "Epoch 361. Testing loss: 0.005095734759899122 Test psnr23.31034466396482 dB\n",
      "Epoch 362. Training loss: 0.003863387543038187 Train psnr 24.718473520201446 dB\n",
      "Epoch 362. Testing loss: 0.003961560848568167 Test psnr24.375736937691613 dB\n",
      "Epoch 363. Training loss: 0.0037860403495040117 Train psnr 24.55560303927343 dB\n",
      "Epoch 363. Testing loss: 0.004696496961904424 Test psnr23.68045519133844 dB\n",
      "Epoch 364. Training loss: 0.003778911671568558 Train psnr 24.698081371763397 dB\n",
      "Epoch 364. Testing loss: 0.003818535412262593 Test psnr24.752888942992367 dB\n",
      "Epoch 365. Training loss: 0.0034996684714171445 Train psnr 24.979173789448584 dB\n",
      "Epoch 365. Testing loss: 0.004705238987558654 Test psnr23.322272747575845 dB\n",
      "Epoch 366. Training loss: 0.0037326559408061336 Train psnr 24.797819983864795 dB\n",
      "Epoch 366. Testing loss: 0.004540726841826524 Test psnr23.779814906360723 dB\n",
      "Epoch 367. Training loss: 0.003938205029586689 Train psnr 24.457524480268546 dB\n",
      "Epoch 367. Testing loss: 0.004763725978721466 Test psnr23.27740693505527 dB\n",
      "Epoch 368. Training loss: 0.0036409090971574187 Train psnr 24.70567570042262 dB\n",
      "Epoch 368. Testing loss: 0.003994237265682646 Test psnr24.209832491122693 dB\n",
      "Epoch 369. Training loss: 0.0035627693001164546 Train psnr 24.907998436534342 dB\n",
      "Epoch 369. Testing loss: 0.0036901752464473248 Test psnr24.562642924556517 dB\n",
      "Epoch 370. Training loss: 0.003503898620246011 Train psnr 24.813952634776008 dB\n",
      "Epoch 370. Testing loss: 0.004852530430071056 Test psnr23.604153432479055 dB\n",
      "Epoch 371. Training loss: 0.0035699187847377176 Train psnr 24.99308178530262 dB\n",
      "Epoch 371. Testing loss: 0.004904918139800429 Test psnr23.372737448533915 dB\n",
      "Epoch 372. Training loss: 0.0036303096138382038 Train psnr 24.996998746602536 dB\n",
      "Epoch 372. Testing loss: 0.004210726790396231 Test psnr23.96142126132483 dB\n",
      "Epoch 373. Training loss: 0.0038505959530818487 Train psnr 24.67239740917164 dB\n",
      "Epoch 373. Testing loss: 0.00444009540868657 Test psnr23.827329265881968 dB\n",
      "Epoch 374. Training loss: 0.0036889460558692613 Train psnr 24.7870091927709 dB\n",
      "Epoch 374. Testing loss: 0.0035981203628970043 Test psnr24.885420861252367 dB\n",
      "Epoch 375. Training loss: 0.003442682951827648 Train psnr 25.18397333049875 dB\n",
      "Epoch 375. Testing loss: 0.005785600282251835 Test psnr22.544066398333634 dB\n",
      "Epoch 376. Training loss: 0.0034707497995297766 Train psnr 25.102315713827213 dB\n",
      "Epoch 376. Testing loss: 0.004205283875178013 Test psnr23.957737606223244 dB\n",
      "Epoch 377. Training loss: 0.0034799381504407186 Train psnr 25.065575808289633 dB\n",
      "Epoch 377. Testing loss: 0.004868401879710811 Test psnr23.21989083446952 dB\n",
      "Epoch 378. Training loss: 0.0036957787253828556 Train psnr 24.75996795861651 dB\n",
      "Epoch 378. Testing loss: 0.004548886591302497 Test psnr23.697587553318076 dB\n",
      "Epoch 379. Training loss: 0.0035178175424797494 Train psnr 24.932663632823623 dB\n",
      "Epoch 379. Testing loss: 0.004967127394463334 Test psnr23.29630060696045 dB\n",
      "Epoch 380. Training loss: 0.00376506516170737 Train psnr 24.921953212313003 dB\n",
      "Epoch 380. Testing loss: 0.0047128278695579085 Test psnr23.467994450906446 dB\n",
      "Epoch 381. Training loss: 0.003501847379211859 Train psnr 25.040240990783513 dB\n",
      "Epoch 381. Testing loss: 0.005574883460732443 Test psnr22.830633767419275 dB\n",
      "Epoch 382. Training loss: 0.0034418391184309464 Train psnr 25.09344838955514 dB\n",
      "Epoch 382. Testing loss: 0.005071015330031514 Test psnr23.478875500413587 dB\n",
      "Epoch 383. Training loss: 0.003616959300799001 Train psnr 24.957385306596738 dB\n",
      "Epoch 383. Testing loss: 0.004904863491122212 Test psnr23.390792094533413 dB\n",
      "Epoch 384. Training loss: 0.0034305044743967684 Train psnr 25.25994155657537 dB\n",
      "Epoch 384. Testing loss: 0.003946456758837614 Test psnr24.393303031571957 dB\n",
      "Epoch 385. Training loss: 0.003998362575657666 Train psnr 24.469215715363905 dB\n",
      "Epoch 385. Testing loss: 0.004488744041217225 Test psnr23.53446479400339 dB\n",
      "Epoch 386. Training loss: 0.0034242582225583887 Train psnr 25.0803324733509 dB\n",
      "Epoch 386. Testing loss: 0.00719580619728991 Test psnr22.68962908428782 dB\n",
      "Epoch 387. Training loss: 0.003436323715855874 Train psnr 25.0892914941834 dB\n",
      "Epoch 387. Testing loss: 0.0037134107468383653 Test psnr24.53421779952828 dB\n",
      "Epoch 388. Training loss: 0.003983756643719971 Train psnr 24.447387032332973 dB\n",
      "Epoch 388. Testing loss: 0.004196681148771729 Test psnr23.950195026613045 dB\n",
      "Epoch 389. Training loss: 0.0033039449644683486 Train psnr 25.30971720799517 dB\n",
      "Epoch 389. Testing loss: 0.004097151270668421 Test psnr24.17949681612753 dB\n",
      "Epoch 390. Training loss: 0.003433385571840693 Train psnr 25.051779142160548 dB\n",
      "Epoch 390. Testing loss: 0.004024496069177985 Test psnr24.528139491164467 dB\n",
      "Epoch 391. Training loss: 0.003789544043237376 Train psnr 24.746412553718624 dB\n",
      "Epoch 391. Testing loss: 0.004389391580064382 Test psnr23.805365515513813 dB\n",
      "Epoch 392. Training loss: 0.0038523341451461115 Train psnr 24.609481698697305 dB\n",
      "Epoch 392. Testing loss: 0.00471540740025895 Test psnr23.469468417529082 dB\n",
      "Epoch 393. Training loss: 0.003763858864100225 Train psnr 24.525008961727874 dB\n",
      "Epoch 393. Testing loss: 0.004090805837352361 Test psnr24.085114515804044 dB\n",
      "Epoch 394. Training loss: 0.0036089124848347224 Train psnr 24.79090350528669 dB\n",
      "Epoch 394. Testing loss: 0.004154161284012454 Test psnr23.981202807239402 dB\n",
      "Epoch 395. Training loss: 0.0033256268759846294 Train psnr 25.26260826302927 dB\n",
      "Epoch 395. Testing loss: 0.0037417451718023847 Test psnr24.613305168194263 dB\n",
      "Epoch 396. Training loss: 0.0038717039391038973 Train psnr 24.621212365248727 dB\n",
      "Epoch 396. Testing loss: 0.004469069984874555 Test psnr23.864817470478158 dB\n",
      "Epoch 397. Training loss: 0.0034631185331626944 Train psnr 24.886921855636576 dB\n",
      "Epoch 397. Testing loss: 0.0045272917154112035 Test psnr23.784300358711683 dB\n",
      "Epoch 398. Training loss: 0.004151710954478435 Train psnr 24.26413180489896 dB\n",
      "Epoch 398. Testing loss: 0.004119585866906813 Test psnr23.983300520355442 dB\n",
      "Epoch 399. Training loss: 0.0037457716014040144 Train psnr 24.685640279846822 dB\n",
      "Epoch 399. Testing loss: 0.0032907426856192096 Test psnr25.05378260960423 dB\n",
      "Epoch 400. Training loss: 0.0036183325012149126 Train psnr 24.78362777910746 dB\n",
      "Epoch 400. Testing loss: 0.004287404340824911 Test psnr24.300630729537506 dB\n",
      "Epoch 401. Training loss: 0.0036825614117429054 Train psnr 24.799878943310315 dB\n",
      "Epoch 401. Testing loss: 0.004207078201164093 Test psnr24.024689255014227 dB\n",
      "Epoch 402. Training loss: 0.003895003124948983 Train psnr 24.674327042111255 dB\n",
      "Epoch 402. Testing loss: 0.0037522906038377967 Test psnr24.485100082316762 dB\n",
      "Epoch 403. Training loss: 0.003572603752999975 Train psnr 24.968616436267176 dB\n",
      "Epoch 403. Testing loss: 0.003971019593466606 Test psnr24.32489758820304 dB\n",
      "Epoch 404. Training loss: 0.003275110022769424 Train psnr 25.25335289612857 dB\n",
      "Epoch 404. Testing loss: 0.00509034120477736 Test psnr23.079682936831148 dB\n",
      "Epoch 405. Training loss: 0.0036858109258964917 Train psnr 24.732760003158056 dB\n",
      "Epoch 405. Testing loss: 0.004658639996445605 Test psnr23.80078469274755 dB\n",
      "Epoch 406. Training loss: 0.0034842760273533172 Train psnr 25.07566291233793 dB\n",
      "Epoch 406. Testing loss: 0.004137422290763685 Test psnr24.22037987541688 dB\n",
      "Epoch 407. Training loss: 0.003526629697788801 Train psnr 24.97526668614557 dB\n",
      "Epoch 407. Testing loss: 0.003931325893583042 Test psnr24.386235976551983 dB\n",
      "Epoch 408. Training loss: 0.003607511054724455 Train psnr 24.899154029422693 dB\n",
      "Epoch 408. Testing loss: 0.004071554934073772 Test psnr24.14729670459251 dB\n",
      "Epoch 409. Training loss: 0.003610271409055904 Train psnr 24.783045445878567 dB\n",
      "Epoch 409. Testing loss: 0.004756215726956725 Test psnr23.476611865914204 dB\n",
      "Epoch 410. Training loss: 0.0036813073031800357 Train psnr 24.80146967448704 dB\n",
      "Epoch 410. Testing loss: 0.0051478976383805275 Test psnr23.179051321522024 dB\n",
      "Epoch 411. Training loss: 0.003336217519908882 Train psnr 25.177183331054827 dB\n",
      "Epoch 411. Testing loss: 0.004147564476755049 Test psnr24.202774652510335 dB\n",
      "Epoch 412. Training loss: 0.0032899001870598447 Train psnr 25.269660119483763 dB\n",
      "Epoch 412. Testing loss: 0.0043350963470792135 Test psnr24.366923539882873 dB\n",
      "Epoch 413. Training loss: 0.003442517587947741 Train psnr 25.0615047423182 dB\n",
      "Epoch 413. Testing loss: 0.00577011880730944 Test psnr22.676572481505747 dB\n",
      "Epoch 414. Training loss: 0.0038433351774552933 Train psnr 24.596053837106012 dB\n",
      "Epoch 414. Testing loss: 0.004111495268132005 Test psnr23.935495192372237 dB\n",
      "Epoch 415. Training loss: 0.00358932820279478 Train psnr 24.781657874289188 dB\n",
      "Epoch 415. Testing loss: 0.00450332195032388 Test psnr24.188848623953493 dB\n",
      "Epoch 416. Training loss: 0.0033294573403780526 Train psnr 25.231754915453397 dB\n",
      "Epoch 416. Testing loss: 0.004984300616862518 Test psnr23.166275755275812 dB\n",
      "Epoch 417. Training loss: 0.00391995956051049 Train psnr 24.561014583510154 dB\n",
      "Epoch 417. Testing loss: 0.0033285057371748345 Test psnr25.09145145657157 dB\n",
      "Epoch 418. Training loss: 0.003448262263350842 Train psnr 25.163898183321965 dB\n",
      "Epoch 418. Testing loss: 0.004352700198069215 Test psnr23.83878169945743 dB\n",
      "Epoch 419. Training loss: 0.0036265955024741984 Train psnr 24.810090607931983 dB\n",
      "Epoch 419. Testing loss: 0.006033766948218856 Test psnr22.71355877261436 dB\n",
      "Epoch 420. Training loss: 0.0036211894526914285 Train psnr 24.78881896692436 dB\n",
      "Epoch 420. Testing loss: 0.005339613716517176 Test psnr23.0215290469836 dB\n",
      "Epoch 421. Training loss: 0.0032735522652633095 Train psnr 25.315738978898032 dB\n",
      "Epoch 421. Testing loss: 0.0034543152931811555 Test psnr24.96187481129487 dB\n",
      "Epoch 422. Training loss: 0.003471855619991721 Train psnr 25.05053869996047 dB\n",
      "Epoch 422. Testing loss: 0.004691775422543287 Test psnr23.538045595143817 dB\n",
      "Epoch 423. Training loss: 0.0037215985357761383 Train psnr 24.63461914156061 dB\n",
      "Epoch 423. Testing loss: 0.005093636423615473 Test psnr23.065713209831205 dB\n",
      "Epoch 424. Training loss: 0.0037210981679157143 Train psnr 24.73944630603472 dB\n",
      "Epoch 424. Testing loss: 0.0059663390607706136 Test psnr22.667231797365133 dB\n",
      "Epoch 425. Training loss: 0.0032676322306016167 Train psnr 25.19775388606346 dB\n",
      "Epoch 425. Testing loss: 0.004721866787544319 Test psnr23.839806922653672 dB\n",
      "Epoch 426. Training loss: 0.0034610225059288112 Train psnr 25.174269021207532 dB\n",
      "Epoch 426. Testing loss: 0.004455790954775044 Test psnr23.760585820408032 dB\n",
      "Epoch 427. Training loss: 0.003597785516544 Train psnr 24.84464468828912 dB\n",
      "Epoch 427. Testing loss: 0.004322256294212171 Test psnr23.87579575060759 dB\n",
      "Epoch 428. Training loss: 0.003736460758087209 Train psnr 24.74384425881151 dB\n",
      "Epoch 428. Testing loss: 0.0028863097707341823 Test psnr25.588350480731915 dB\n",
      "模型更新成功\n",
      "Epoch 429. Training loss: 0.003846716076511432 Train psnr 24.709284777499523 dB\n",
      "Epoch 429. Testing loss: 0.004603384228955422 Test psnr23.558505944625352 dB\n",
      "Epoch 430. Training loss: 0.003102556401005897 Train psnr 25.484852085586294 dB\n",
      "Epoch 430. Testing loss: 0.004652573959901929 Test psnr23.49140453332959 dB\n",
      "Epoch 431. Training loss: 0.003704154157292163 Train psnr 24.830541280209065 dB\n",
      "Epoch 431. Testing loss: 0.004157323024368712 Test psnr24.123995036811966 dB\n",
      "Epoch 432. Training loss: 0.0037205667733296493 Train psnr 24.694191124125002 dB\n",
      "Epoch 432. Testing loss: 0.0039009668731263708 Test psnr24.277635396914253 dB\n",
      "Epoch 433. Training loss: 0.0037398140636485137 Train psnr 24.692558626501413 dB\n",
      "Epoch 433. Testing loss: 0.004369174230045506 Test psnr23.693934616240508 dB\n",
      "Epoch 434. Training loss: 0.003548422570977556 Train psnr 24.901273411595312 dB\n",
      "Epoch 434. Testing loss: 0.004687765380367637 Test psnr23.63411088107503 dB\n",
      "Epoch 435. Training loss: 0.003734537953788643 Train psnr 24.78434016244631 dB\n",
      "Epoch 435. Testing loss: 0.005003919758434806 Test psnr23.27349140019516 dB\n",
      "Epoch 436. Training loss: 0.0036775575738334865 Train psnr 24.74236612841382 dB\n",
      "Epoch 436. Testing loss: 0.004777526615985802 Test psnr23.56681146240013 dB\n",
      "Epoch 437. Training loss: 0.003758767103008403 Train psnr 24.528694402019024 dB\n",
      "Epoch 437. Testing loss: 0.004321179718577436 Test psnr23.88011062920471 dB\n",
      "Epoch 438. Training loss: 0.0032963988048498307 Train psnr 25.09038158436756 dB\n",
      "Epoch 438. Testing loss: 0.006542887704979096 Test psnr22.668652557070423 dB\n",
      "Epoch 439. Training loss: 0.003764047250641804 Train psnr 24.594151682055184 dB\n",
      "Epoch 439. Testing loss: 0.003907722088375262 Test psnr24.24978271001627 dB\n",
      "Epoch 440. Training loss: 0.0037620345665664787 Train psnr 24.77576846980686 dB\n",
      "Epoch 440. Testing loss: 0.0039579377709222695 Test psnr24.502322634673416 dB\n",
      "Epoch 441. Training loss: 0.0033673719531578713 Train psnr 25.10836593135895 dB\n",
      "Epoch 441. Testing loss: 0.004858081794476935 Test psnr23.23561320526351 dB\n",
      "Epoch 442. Training loss: 0.00360092056380062 Train psnr 24.973985780535248 dB\n",
      "Epoch 442. Testing loss: 0.004399017231272799 Test psnr23.87590074706169 dB\n",
      "Epoch 443. Training loss: 0.0036728603340554656 Train psnr 24.73040532743513 dB\n",
      "Epoch 443. Testing loss: 0.00422876827152712 Test psnr23.954994225214303 dB\n",
      "Epoch 444. Training loss: 0.0037892865805412854 Train psnr 24.71111178348513 dB\n",
      "Epoch 444. Testing loss: 0.0038240556605160236 Test psnr24.670366898721657 dB\n",
      "Epoch 445. Training loss: 0.00370250255065529 Train psnr 24.713049001631656 dB\n",
      "Epoch 445. Testing loss: 0.004069979169539043 Test psnr24.24737379645614 dB\n",
      "Epoch 446. Training loss: 0.0037271280960882443 Train psnr 24.746745646904653 dB\n",
      "Epoch 446. Testing loss: 0.005097770198647465 Test psnr23.336954561543113 dB\n",
      "Epoch 447. Training loss: 0.0032311495252590823 Train psnr 25.306487126981068 dB\n",
      "Epoch 447. Testing loss: 0.0036886261576520546 Test psnr24.653868614222908 dB\n",
      "Epoch 448. Training loss: 0.0035540747411320346 Train psnr 24.845935616364052 dB\n",
      "Epoch 448. Testing loss: 0.005603974984426584 Test psnr22.90048581352375 dB\n",
      "Epoch 449. Training loss: 0.003585414336013951 Train psnr 24.9734537703913 dB\n",
      "Epoch 449. Testing loss: 0.0037479818066848175 Test psnr24.62351585151738 dB\n",
      "Epoch 450. Training loss: 0.003411174135021212 Train psnr 25.18416784742412 dB\n",
      "Epoch 450. Testing loss: 0.004680200612970761 Test psnr23.624455443688582 dB\n",
      "Epoch 451. Training loss: 0.00322968202536893 Train psnr 25.13790472124148 dB\n",
      "Epoch 451. Testing loss: 0.004283508186095527 Test psnr23.86734665795452 dB\n",
      "Epoch 452. Training loss: 0.0035573039152822865 Train psnr 24.991180123934036 dB\n",
      "Epoch 452. Testing loss: 0.0040641055176300666 Test psnr24.30876842443468 dB\n",
      "Epoch 453. Training loss: 0.0036139189482160042 Train psnr 24.818384280065242 dB\n",
      "Epoch 453. Testing loss: 0.004568052478134632 Test psnr23.63223744285005 dB\n",
      "Epoch 454. Training loss: 0.002929177544725111 Train psnr 25.861192167072698 dB\n",
      "Epoch 454. Testing loss: 0.00395518125567053 Test psnr24.53040087786839 dB\n",
      "Epoch 455. Training loss: 0.0034211743316662157 Train psnr 25.043731043191134 dB\n",
      "Epoch 455. Testing loss: 0.004485374815495951 Test psnr23.72274481263938 dB\n",
      "Epoch 456. Training loss: 0.003505964255421994 Train psnr 25.083011526319382 dB\n",
      "Epoch 456. Testing loss: 0.00477643806620368 Test psnr23.45647032942973 dB\n",
      "Epoch 457. Training loss: 0.0033154883238143825 Train psnr 25.14685415783501 dB\n",
      "Epoch 457. Testing loss: 0.004586167367441314 Test psnr23.57793726276788 dB\n",
      "Epoch 458. Training loss: 0.003437111109266417 Train psnr 25.067007104130802 dB\n",
      "Epoch 458. Testing loss: 0.004268810818237918 Test psnr23.979970956039676 dB\n",
      "Epoch 459. Training loss: 0.0037800445029381336 Train psnr 24.639548935366335 dB\n",
      "Epoch 459. Testing loss: 0.004212767384680254 Test psnr24.33128361078547 dB\n",
      "Epoch 460. Training loss: 0.0032576242331088636 Train psnr 25.21856638565173 dB\n",
      "Epoch 460. Testing loss: 0.003858073115614908 Test psnr24.415292894064844 dB\n",
      "Epoch 461. Training loss: 0.0034827800557474817 Train psnr 24.993902765522087 dB\n",
      "Epoch 461. Testing loss: 0.004812730043860418 Test psnr23.386703319577173 dB\n",
      "Epoch 462. Training loss: 0.003495221442886089 Train psnr 24.95606238523969 dB\n",
      "Epoch 462. Testing loss: 0.004627679807267019 Test psnr23.594108058507913 dB\n",
      "Epoch 463. Training loss: 0.003430167322349326 Train psnr 25.038687031135254 dB\n",
      "Epoch 463. Testing loss: 0.004748094959982804 Test psnr23.50685546293349 dB\n",
      "Epoch 464. Training loss: 0.003583348584933239 Train psnr 24.933568818218586 dB\n",
      "Epoch 464. Testing loss: 0.003825825688961361 Test psnr24.465273611314228 dB\n",
      "Epoch 465. Training loss: 0.004034943651947144 Train psnr 24.357779984057185 dB\n",
      "Epoch 465. Testing loss: 0.00453472084232739 Test psnr23.546046058888354 dB\n",
      "Epoch 466. Training loss: 0.003901537638484386 Train psnr 24.508302678590617 dB\n",
      "Epoch 466. Testing loss: 0.004649656458890864 Test psnr23.658053601184914 dB\n",
      "Epoch 467. Training loss: 0.003412392183427552 Train psnr 25.084338279747968 dB\n",
      "Epoch 467. Testing loss: 0.0040874921916318795 Test psnr24.11950289054274 dB\n",
      "Epoch 468. Training loss: 0.003651194807485138 Train psnr 24.77530806080728 dB\n",
      "Epoch 468. Testing loss: 0.004821313046185034 Test psnr23.383213047790438 dB\n",
      "Epoch 469. Training loss: 0.0034090153109118866 Train psnr 25.064708927037106 dB\n",
      "Epoch 469. Testing loss: 0.004004158245931778 Test psnr24.175619895809046 dB\n",
      "Epoch 470. Training loss: 0.003549425314862706 Train psnr 25.18468013489914 dB\n",
      "Epoch 470. Testing loss: 0.004107926672856722 Test psnr24.288269219278284 dB\n",
      "Epoch 471. Training loss: 0.004006909845772674 Train psnr 24.54056371153186 dB\n",
      "Epoch 471. Testing loss: 0.005380219813170177 Test psnr23.01356888042056 dB\n",
      "Epoch 472. Training loss: 0.003505190993708215 Train psnr 25.038374983395364 dB\n",
      "Epoch 472. Testing loss: 0.0060550919733941555 Test psnr22.474038456222875 dB\n",
      "Epoch 473. Training loss: 0.0033679130934423916 Train psnr 25.148882826399507 dB\n",
      "Epoch 473. Testing loss: 0.004302091364349637 Test psnr23.94673413507713 dB\n",
      "Epoch 474. Training loss: 0.004216217656472796 Train psnr 24.25692964386239 dB\n",
      "Epoch 474. Testing loss: 0.0072796451193945745 Test psnr22.283108139196845 dB\n",
      "Epoch 475. Training loss: 0.0037576698089475955 Train psnr 24.601588705134287 dB\n",
      "Epoch 475. Testing loss: 0.003868382191285491 Test psnr24.279129981467758 dB\n",
      "Epoch 476. Training loss: 0.003586773954642316 Train psnr 24.83230219335064 dB\n",
      "Epoch 476. Testing loss: 0.004293635221464294 Test psnr23.82936252988602 dB\n",
      "Epoch 477. Training loss: 0.0034550500823299223 Train psnr 25.156578539876385 dB\n",
      "Epoch 477. Testing loss: 0.0036284091682838543 Test psnr24.53615895575607 dB\n",
      "Epoch 478. Training loss: 0.0034643331779526513 Train psnr 25.056449932702954 dB\n",
      "Epoch 478. Testing loss: 0.004386288812384009 Test psnr23.638933855890837 dB\n",
      "Epoch 479. Training loss: 0.003356788327341507 Train psnr 25.227319590494528 dB\n",
      "Epoch 479. Testing loss: 0.0041092571004160815 Test psnr24.16494243661938 dB\n",
      "Epoch 480. Training loss: 0.003971026037010904 Train psnr 24.422156420300556 dB\n",
      "Epoch 480. Testing loss: 0.004699355590024165 Test psnr23.374097835261654 dB\n",
      "Epoch 481. Training loss: 0.0037590563031763098 Train psnr 24.83110892702631 dB\n",
      "Epoch 481. Testing loss: 0.005419616188321795 Test psnr23.239050454227392 dB\n",
      "Epoch 482. Training loss: 0.0035285133410964094 Train psnr 25.029938949275355 dB\n",
      "Epoch 482. Testing loss: 0.005154062428378633 Test psnr23.612383552944177 dB\n",
      "Epoch 483. Training loss: 0.0037118351677220248 Train psnr 24.778031530206693 dB\n",
      "Epoch 483. Testing loss: 0.0054999917878636295 Test psnr23.207545076699603 dB\n",
      "Epoch 484. Training loss: 0.003561342965296813 Train psnr 25.065677418041044 dB\n",
      "Epoch 484. Testing loss: 0.004762370605021715 Test psnr23.52273045039939 dB\n",
      "Epoch 485. Training loss: 0.0034925512797934445 Train psnr 24.99981060024622 dB\n",
      "Epoch 485. Testing loss: 0.004056457064247557 Test psnr24.039915772723567 dB\n",
      "Epoch 486. Training loss: 0.003710712221442934 Train psnr 24.665523898691973 dB\n",
      "Epoch 486. Testing loss: 0.003420491852531476 Test psnr25.04151068268998 dB\n",
      "Epoch 487. Training loss: 0.003479965208833547 Train psnr 24.932183446532502 dB\n",
      "Epoch 487. Testing loss: 0.004414317065051624 Test psnr24.23702505369268 dB\n",
      "Epoch 488. Training loss: 0.0034504437210495795 Train psnr 25.246579589675296 dB\n",
      "Epoch 488. Testing loss: 0.004070356122351119 Test psnr24.086093648372117 dB\n",
      "Epoch 489. Training loss: 0.0034904368517904034 Train psnr 25.008408770381887 dB\n",
      "Epoch 489. Testing loss: 0.004369077272713184 Test psnr23.8484260932975 dB\n",
      "Epoch 490. Training loss: 0.003674108814856593 Train psnr 24.731420728815717 dB\n",
      "Epoch 490. Testing loss: 0.005168933487896409 Test psnr22.904538855578974 dB\n",
      "Epoch 491. Training loss: 0.00333092054924029 Train psnr 25.239712073490317 dB\n",
      "Epoch 491. Testing loss: 0.004311877968055862 Test psnr23.98547656501872 dB\n",
      "Epoch 492. Training loss: 0.003509467204199418 Train psnr 25.1145588372408 dB\n",
      "Epoch 492. Testing loss: 0.0046774128651512524 Test psnr23.442154938025904 dB\n",
      "Epoch 493. Training loss: 0.003709900509484374 Train psnr 24.68259045806332 dB\n",
      "Epoch 493. Testing loss: 0.0041421717199097785 Test psnr24.44303748288376 dB\n",
      "Epoch 494. Training loss: 0.0035168886248005977 Train psnr 24.87653692560913 dB\n",
      "Epoch 494. Testing loss: 0.004687724269128272 Test psnr23.608355343108236 dB\n",
      "Epoch 495. Training loss: 0.003657434166311041 Train psnr 24.757970201419173 dB\n",
      "Epoch 495. Testing loss: 0.0045805250161460465 Test psnr23.82751435257551 dB\n",
      "Epoch 496. Training loss: 0.003999404018957233 Train psnr 24.427311625912424 dB\n",
      "Epoch 496. Testing loss: 0.004004814296162554 Test psnr24.752276157697473 dB\n",
      "Epoch 497. Training loss: 0.003737967763618942 Train psnr 24.81370141846983 dB\n",
      "Epoch 497. Testing loss: 0.0038065993825771977 Test psnr24.240427904566356 dB\n",
      "Epoch 498. Training loss: 0.003298511585678186 Train psnr 25.19360080664505 dB\n",
      "Epoch 498. Testing loss: 0.004918917348342282 Test psnr23.616317354660065 dB\n",
      "Epoch 499. Training loss: 0.003635452823353964 Train psnr 24.77033985583736 dB\n",
      "Epoch 499. Testing loss: 0.0038189496845006943 Test psnr24.343171592785332 dB\n",
      "Epoch 500. Training loss: 0.0035913542930134817 Train psnr 25.119040050900427 dB\n",
      "Epoch 500. Testing loss: 0.005060872761532664 Test psnr23.10254022848456 dB\n",
      "Epoch 501. Training loss: 0.0037940146223838 Train psnr 24.671401089148503 dB\n",
      "Epoch 501. Testing loss: 0.005300202539988926 Test psnr23.014523331600124 dB\n",
      "Epoch 502. Training loss: 0.003532120136936244 Train psnr 24.770103607427473 dB\n",
      "Epoch 502. Testing loss: 0.0040426231322011775 Test psnr24.158725732324292 dB\n",
      "Epoch 503. Training loss: 0.0036492208018898964 Train psnr 24.808021071560496 dB\n",
      "Epoch 503. Testing loss: 0.00395150826911309 Test psnr24.635547979749077 dB\n",
      "Epoch 504. Training loss: 0.003673429231224745 Train psnr 24.704451796713208 dB\n",
      "Epoch 504. Testing loss: 0.005472504134689059 Test psnr23.03216726462188 dB\n",
      "Epoch 505. Training loss: 0.0036024491151022773 Train psnr 25.098043246148634 dB\n",
      "Epoch 505. Testing loss: 0.005139109745089497 Test psnr23.12253040478575 dB\n",
      "Epoch 506. Training loss: 0.0038461954161328705 Train psnr 24.540931728957347 dB\n",
      "Epoch 506. Testing loss: 0.003121890909304576 Test psnr25.51925866994967 dB\n",
      "Epoch 507. Training loss: 0.0032181309591243533 Train psnr 25.527139439044937 dB\n",
      "Epoch 507. Testing loss: 0.005052246236508446 Test psnr23.46773131049955 dB\n",
      "Epoch 508. Training loss: 0.003516309167536204 Train psnr 25.061352957482796 dB\n",
      "Epoch 508. Testing loss: 0.004498508027089494 Test psnr23.71401549172148 dB\n",
      "Epoch 509. Training loss: 0.0036648829026441824 Train psnr 24.760653270512258 dB\n",
      "Epoch 509. Testing loss: 0.005069431383162737 Test psnr23.25883716698815 dB\n",
      "Epoch 510. Training loss: 0.0038924661726413064 Train psnr 24.489578386487075 dB\n",
      "Epoch 510. Testing loss: 0.004278145497664809 Test psnr24.007399597488384 dB\n",
      "Epoch 511. Training loss: 0.003850876623274464 Train psnr 24.56779191730937 dB\n",
      "Epoch 511. Testing loss: 0.005890759340088282 Test psnr22.854508582587876 dB\n",
      "Epoch 512. Training loss: 0.0034062848160892984 Train psnr 25.223220001739563 dB\n",
      "Epoch 512. Testing loss: 0.0038478242100349496 Test psnr24.372696949588594 dB\n",
      "Epoch 513. Training loss: 0.003618076651994335 Train psnr 24.85274408490555 dB\n",
      "Epoch 513. Testing loss: 0.004163194614063416 Test psnr23.91198918689488 dB\n",
      "Epoch 514. Training loss: 0.0034660873281066877 Train psnr 24.988087974312034 dB\n",
      "Epoch 514. Testing loss: 0.00483730252433036 Test psnr23.334582108883545 dB\n",
      "Epoch 515. Training loss: 0.003832277529382784 Train psnr 24.50676540415931 dB\n",
      "Epoch 515. Testing loss: 0.004213013619716678 Test psnr24.168523242759033 dB\n",
      "Epoch 516. Training loss: 0.003796484806419661 Train psnr 24.71519005173961 dB\n",
      "Epoch 516. Testing loss: 0.004307308566889593 Test psnr23.84194592928348 dB\n",
      "Epoch 517. Training loss: 0.003500174508397386 Train psnr 25.017074451054192 dB\n",
      "Epoch 517. Testing loss: 0.004226194395284567 Test psnr24.341069452664577 dB\n",
      "Epoch 518. Training loss: 0.003798161072681021 Train psnr 24.778657092169063 dB\n",
      "Epoch 518. Testing loss: 0.004678091200600777 Test psnr23.767125099657083 dB\n",
      "Epoch 519. Training loss: 0.003916478109251904 Train psnr 24.49775835578383 dB\n",
      "Epoch 519. Testing loss: 0.004140517108940652 Test psnr24.10390707411513 dB\n",
      "Epoch 520. Training loss: 0.0035058840493500036 Train psnr 24.989935691990684 dB\n",
      "Epoch 520. Testing loss: 0.004113356782389539 Test psnr24.041278942656096 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import log10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "    \n",
    "    train_path = 'train/DIV2K_train_HR'\n",
    "    test_path = 'DIV2K_test'\n",
    "\n",
    "    crop_size = 96  # 、图像裁剪尺寸\n",
    "    scaling_factor = 2  # 放大倍数\n",
    "\n",
    "    # 学习参数\n",
    "    checkpoint_dir = 'checkpoints'  # 模型保存路径及预训练模型路径\n",
    "    # 定义保存的文件路径，包括文件名\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'edsr_NAF_1.pth')\n",
    "    batch_size = 16\n",
    "    start_epoch = 0 \n",
    "    epochs = 5000\n",
    "    workers = 4 \n",
    "    lr = 1e-4 \n",
    "\n",
    "     # 检查GPU是否可用\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # 先前的psnr\n",
    "    pre_psnr = 0\n",
    "\n",
    "    try:\n",
    "        model = torch.load(checkpoint_path)\n",
    "        model = model.to(device)\n",
    "        print('加载先前模型成功')\n",
    "    except:\n",
    "        print('未加载原有模型训练')\n",
    "        model = EDSR()\n",
    "        model = model.to(device)\n",
    "\n",
    "    # 初始化优化器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "\n",
    "    # 采用L1损失\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    train_dataset = SRDataset(train_path, crop_size, scaling_factor)\n",
    "    test_dataset = SRDataset(test_path, crop_size, scaling_factor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=workers,\n",
    "                              )\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=workers,\n",
    "                             )\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "\n",
    "        model.train()  # 训练模式\n",
    "        train_loss = 0\n",
    "        n_iter_train = len(train_loader)\n",
    "        train_psnr = 0\n",
    "        # 按批处理\n",
    "        for i, (lr_imgs, hr_imgs) in enumerate(train_loader):\n",
    "            lr_imgs = lr_imgs.to(device)\n",
    "            hr_imgs = hr_imgs.to(device)\n",
    "\n",
    "            sr_imgs = model(lr_imgs)\n",
    "            loss = criterion(sr_imgs, hr_imgs)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            psnr = 10 * log10(1 / loss.item())\n",
    "            train_psnr += psnr\n",
    "\n",
    "        epoch_loss_train = train_loss / n_iter_train\n",
    "        train_psnr = train_psnr / n_iter_train\n",
    "\n",
    "        print(f\"Epoch {epoch}. Training loss: {epoch_loss_train} Train psnr {train_psnr} dB\")\n",
    "\n",
    "        model.eval()  # 测试模式\n",
    "        test_loss = 0\n",
    "        all_psnr = 0\n",
    "        n_iter_test = len(test_loader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (lr_imgs, hr_imgs) in enumerate(test_loader):\n",
    "                lr_imgs = lr_imgs.to(device)\n",
    "                hr_imgs = hr_imgs.to(device)\n",
    "\n",
    "                sr_imgs = model(lr_imgs)\n",
    "                loss = criterion(sr_imgs, hr_imgs)\n",
    "\n",
    "                psnr = 10 * log10(1 / loss.item())\n",
    "                all_psnr += psnr\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        epoch_loss_test = test_loss / n_iter_test\n",
    "        epoch_psnr = all_psnr / n_iter_test\n",
    "\n",
    "        print(f\"Epoch {epoch}. Testing loss: {epoch_loss_test} Test psnr{epoch_psnr} dB\")\n",
    "\n",
    "        if epoch_psnr > pre_psnr:\n",
    "            torch.save(model, checkpoint_path)\n",
    "            pre_psnr = epoch_psnr\n",
    "            print('模型更新成功')\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e4b609-4ba6-4c78-b146-4cf638e86cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     14\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     15\u001b[0m ])\n\u001b[1;32m     17\u001b[0m test_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m ds\u001b[38;5;241m=\u001b[39mSRDataset(\u001b[43mtrain_path\u001b[49m,\u001b[38;5;241m96\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     19\u001b[0m l,h\u001b[38;5;241m=\u001b[39mds[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# img = input_transform(imgO).unsqueeze(0).to(device)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_path' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "imgO = Image.open('0811x2.png').convert(\"RGB\")  # 测试图片的路径\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_path='test'\n",
    "ds=SRDataset(train_path,96,2)\n",
    "l,h=ds[1]\n",
    "\n",
    "# img = input_transform(imgO).unsqueeze(0).to(device)\n",
    "img = transform(imgO).unsqueeze(0).to(device)  # 将图像移到GPU\n",
    "\n",
    "# 导入模型\n",
    "net = torch.load(\"checkpoints/edsr_NAF_1.pth\").to(device)  # 将模型移到GPU\n",
    "net.eval()  # 设置模型为评估模式\n",
    "\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    source = net(img)[0, :, :, :]\n",
    "\n",
    "source = source.cpu().detach().numpy()  # 转为numpy并移到CPU\n",
    "source = source.transpose((1, 2, 0))  # 切换形状\n",
    "source = np.clip(source, 0, 1)  # 修正图片\n",
    "img = Image.fromarray(np.uint8(source * 255))\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imgO)\n",
    "plt.title('input')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img)\n",
    "plt.title('output')\n",
    "plt.show()\n",
    "\n",
    "img.save('./result_NAF.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6355f-d12b-4708-876d-6e0b5d48a23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esdr",
   "language": "python",
   "name": "esdr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
